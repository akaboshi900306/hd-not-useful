{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<!----------------------------------------------------------------------------------------------\n",
       "------------------------------------------------------------------------------------------------\n",
       "IF YOU CAN SEE THIS CELL, CLICK IN IT, PRESS CTRL+ENTER, THEN REFRESH THE PAGE TO START THE TOOL\n",
       "------------------------------------------------------------------------------------------------\n",
       "----------------------------------------------------------------------------------------------->\n",
       "\n",
       "<style>\n",
       "/*these styles make the notebook look more like an application*/\n",
       "#site {height: 100% !important;}\n",
       "#notebook-container {width: 90% !important;}\n",
       "h1, h2, p {margin: 0px !important;}\n",
       ".anchor-link {display: none !important;}\n",
       ".cell {padding: 0px !important;}\n",
       ".output_subarea {padding: 2px !important;}\n",
       ".output_javascript {padding: 0px !important;}\n",
       ".output_html {padding: 0px !important;}\n",
       ".text_cell_render {padding: 2px 0px !important; margin-top: 5px !important; border: 0 !important;}\n",
       "h1, h2 {margin-top: 15px !important;}\n",
       "h2 {border-bottom: thin solid !important;}\n",
       "ul, .widget-button {margin: 0px !important;}\n",
       ".run_this_cell {padding-top: 0px !important; padding-top: 0px !important;}\n",
       "\n",
       "/*these styles are specific to this page*/\n",
       ".fit-label {text-align: center !important; font-size: .6vw !important;}\n",
       "::-webkit-clear-button {font-size: 12px !important;}\n",
       "::-webkit-inner-spin-button {display: none !important;}\n",
       "::-webkit-calendar-picker-indicator {font-size: 12px !important;}\n",
       "input[type=\"date\"] {font-size: 12px !important;}\n",
       ".widget-toggle-button {height: 40px !important; line-height: normal !important;}\n",
       ".widget-toggle-button.mod-active {background-color: rgb(249, 99, 2) !important; font-weight: bold !important;}\n",
       "option {font-family: monospace !important;}\n",
       "</style>\n",
       "\n",
       "<script>\n",
       "    code_show = true; \n",
       "    function code_toggle() {\n",
       "        if (code_show) {\n",
       "        $('div.input, bdi, #header, .ctb_hideshow').hide();\n",
       "        } else {\n",
       "        $('div.input, bdi, #header, .ctb_hideshow').show();\n",
       "        }\n",
       "        code_show = !code_show\n",
       "    }\n",
       "    \n",
       "    function getCellsByTag(tag) {\n",
       "        return Jupyter.notebook.get_cells().filter(function(c) {return (c.metadata.tags || []).includes(tag)})\n",
       "    }\n",
       "\n",
       "    function execCellsByTag(tag) {\n",
       "        getCellsByTag(tag).forEach(c => c.execute())\n",
       "    }\n",
       "    \n",
       "    function clearCellsByTag(tag) {\n",
       "        getCellsByTag(tag).forEach(c => c.clear_output())\n",
       "    }\n",
       "    \n",
       "    function showMarkdown() { //show markdown cells above lowest output of code cell - avoid having instructions on screen with no options\n",
       "        var max_i = Math.max.apply(null, Jupyter.notebook.get_cells().map((c, i) => ((c.output_area || {})['outputs'] || []).length >= 1 ? i : 0));\n",
       "        Jupyter.notebook.get_cells().filter((c, i) => c.cell_type == 'markdown' & i <= max_i).map(c => $(c.inner_cell).find('.text_cell_render').show())\n",
       "    }\n",
       "    \n",
       "    function clearAllCells() {\n",
       "        Jupyter.notebook.clear_cells_outputs(Array.from(Array(Jupyter.notebook.get_cells().length).keys().slice(1)))\n",
       "    }\n",
       "    \n",
       "    function interruptCell() {\n",
       "        Jupyter.notebook.kernel.interrupt()\n",
       "    }\n",
       "\n",
       "    $(document).ready(function() {\n",
       "        code_toggle(); //when page is ready, hide code\n",
       "        $('.text_cell_render').hide(); //hide markdown\n",
       "        Jupyter.notebook.clear_cells_outputs(Array.from(Array(Jupyter.notebook.get_cells().length).keys()).slice(1)); //clear all output except this cell\n",
       "    });\n",
       "    \n",
       "    init = true;\n",
       "    Jupyter.notebook.events.on('kernel_ready.Kernel', () => {\n",
       "        if (init) {\n",
       "            execCellsByTag('imports');\n",
       "            init = false;\n",
       "        }\n",
       "    });\n",
       "    \n",
       "    Jupyter.notebook.events.on('finished_iopub.Kernel', () => \n",
       "        showMarkdown()\n",
       "    );\n",
       "</script>\n",
       "<a href=\"javascript:code_toggle()\">Click here to show/hide the Python code used to build the tool</a>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "\n",
    "<!----------------------------------------------------------------------------------------------\n",
    "------------------------------------------------------------------------------------------------\n",
    "IF YOU CAN SEE THIS CELL, CLICK IN IT, PRESS CTRL+ENTER, THEN REFRESH THE PAGE TO START THE TOOL\n",
    "------------------------------------------------------------------------------------------------\n",
    "----------------------------------------------------------------------------------------------->\n",
    "\n",
    "<style>\n",
    "/*these styles make the notebook look more like an application*/\n",
    "#site {height: 100% !important;}\n",
    "#notebook-container {width: 90% !important;}\n",
    "h1, h2, p {margin: 0px !important;}\n",
    ".anchor-link {display: none !important;}\n",
    ".cell {padding: 0px !important;}\n",
    ".output_subarea {padding: 2px !important;}\n",
    ".output_javascript {padding: 0px !important;}\n",
    ".output_html {padding: 0px !important;}\n",
    ".text_cell_render {padding: 2px 0px !important; margin-top: 5px !important; border: 0 !important;}\n",
    "h1, h2 {margin-top: 15px !important;}\n",
    "h2 {border-bottom: thin solid !important;}\n",
    "ul, .widget-button {margin: 0px !important;}\n",
    ".run_this_cell {padding-top: 0px !important; padding-top: 0px !important;}\n",
    "\n",
    "/*these styles are specific to this page*/\n",
    ".fit-label {text-align: center !important; font-size: .6vw !important;}\n",
    "::-webkit-clear-button {font-size: 12px !important;}\n",
    "::-webkit-inner-spin-button {display: none !important;}\n",
    "::-webkit-calendar-picker-indicator {font-size: 12px !important;}\n",
    "input[type=\"date\"] {font-size: 12px !important;}\n",
    ".widget-toggle-button {height: 40px !important; line-height: normal !important;}\n",
    ".widget-toggle-button.mod-active {background-color: rgb(249, 99, 2) !important; font-weight: bold !important;}\n",
    "option {font-family: monospace !important;}\n",
    "</style>\n",
    "\n",
    "<script>\n",
    "    code_show = true; \n",
    "    function code_toggle() {\n",
    "        if (code_show) {\n",
    "        $('div.input, bdi, #header, .ctb_hideshow').hide();\n",
    "        } else {\n",
    "        $('div.input, bdi, #header, .ctb_hideshow').show();\n",
    "        }\n",
    "        code_show = !code_show\n",
    "    }\n",
    "    \n",
    "    function getCellsByTag(tag) {\n",
    "        return Jupyter.notebook.get_cells().filter(function(c) {return (c.metadata.tags || []).includes(tag)})\n",
    "    }\n",
    "\n",
    "    function execCellsByTag(tag) {\n",
    "        getCellsByTag(tag).forEach(c => c.execute())\n",
    "    }\n",
    "    \n",
    "    function clearCellsByTag(tag) {\n",
    "        getCellsByTag(tag).forEach(c => c.clear_output())\n",
    "    }\n",
    "    \n",
    "    function showMarkdown() { //show markdown cells above lowest output of code cell - avoid having instructions on screen with no options\n",
    "        var max_i = Math.max.apply(null, Jupyter.notebook.get_cells().map((c, i) => ((c.output_area || {})['outputs'] || []).length >= 1 ? i : 0));\n",
    "        Jupyter.notebook.get_cells().filter((c, i) => c.cell_type == 'markdown' & i <= max_i).map(c => $(c.inner_cell).find('.text_cell_render').show())\n",
    "    }\n",
    "    \n",
    "    function clearAllCells() {\n",
    "        Jupyter.notebook.clear_cells_outputs(Array.from(Array(Jupyter.notebook.get_cells().length).keys().slice(1)))\n",
    "    }\n",
    "    \n",
    "    function interruptCell() {\n",
    "        Jupyter.notebook.kernel.interrupt()\n",
    "    }\n",
    "\n",
    "    $(document).ready(function() {\n",
    "        code_toggle(); //when page is ready, hide code\n",
    "        $('.text_cell_render').hide(); //hide markdown\n",
    "        Jupyter.notebook.clear_cells_outputs(Array.from(Array(Jupyter.notebook.get_cells().length).keys()).slice(1)); //clear all output except this cell\n",
    "    });\n",
    "    \n",
    "    init = true;\n",
    "    Jupyter.notebook.events.on('kernel_ready.Kernel', () => {\n",
    "        if (init) {\n",
    "            execCellsByTag('imports');\n",
    "            init = false;\n",
    "        }\n",
    "    });\n",
    "    \n",
    "    Jupyter.notebook.events.on('finished_iopub.Kernel', () => \n",
    "        showMarkdown()\n",
    "    );\n",
    "</script>\n",
    "<a href=\"javascript:code_toggle()\">Click here to show/hide the Python code used to build the tool</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "imports"
    ]
   },
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from IPython.display import HTML, Javascript, display, clear_output\n",
    "\n",
    "widgets.Widget.close_all() #notebook is doing something like looking for widget state to restore, which can overwrite newly created widgets depending on when it completes (??) this seems to prevent that by removing previous state\n",
    "\n",
    "import sys\n",
    "import datetime\n",
    "import re\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import os\n",
    "\n",
    "#this code hides long confusing error messages from the user - run the last commented line to restore default behavior\n",
    "ipython = get_ipython()\n",
    "if not hasattr(ipython, 'orig_showtraceback'):\n",
    "    ipython.orig_showtraceback = ipython._showtraceback\n",
    "ipython._showtraceback = lambda exception_type, exception, traceback: print(exception, file=sys.stderr)\n",
    "ipython._showtraceback = ipython.orig_showtraceback\n",
    "\n",
    "\n",
    "client = bigquery.Client(project='analytics-supplychain-thd')#May have to specify project here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supply Chain Data Science Forecasting Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "imports"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "clearCellsByTag('imports')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "execCellsByTag('makeUI')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#diplay formatted widget with desired description\n",
    "def display_with_description(widget, description, width=.15):\n",
    "    width_string = str(int(width * 100))+'%'\n",
    "    other_width_string = str(int((1-width) * 100))+'%'\n",
    "    label = widgets.Label(value=description, layout=widgets.Layout(width=width_string))\n",
    "    widget.layout.width = other_width_string\n",
    "    display(widgets.HBox([label, widget]))\n",
    "\n",
    "#string replace queries with inputs\n",
    "def genericReplace(query,replaceDict):\n",
    "    for i,j in replaceDict.items():\n",
    "        query = query.replace(i,str(j))\n",
    "    return query\n",
    "\n",
    "global outputCode\n",
    "outputCode = {'createForecast' : '', 'insertForecast' : '', 'ensemble': '', 'adjustments' : ''}\n",
    "\n",
    "#exec query and append to dictionary to be exported\n",
    "\n",
    "######altSQL = indicator that code is run for current_date only\n",
    "def exec_sql(sql, stringReplaceDict, codeBlock, altSQL=None):\n",
    "    newReplaceDict = stringReplaceDict.copy()\n",
    "    sql = genericReplace(sql, newReplaceDict)\n",
    "    if altSQL == None:\n",
    "        outputCode[codeBlock] += sql\n",
    "    else:#if SQL run will be changed for BQA export\n",
    "        altSQL = genericReplace(altSQL, newReplaceDict)\n",
    "        outputCode[codeBlock] += altSQL\n",
    "    client.query(sql).result()\n",
    "\n",
    "#concatenate inputs columns into single column\n",
    "def make_hierarchy(l):\n",
    "    return ''', '|', '''.join(['CAST({} AS STRING)'.format(c) for c in l])\n",
    "\n",
    "display(Javascript(\"clearCellsByTag('imports')\"))\n",
    "\n",
    "display(Javascript(\"execCellsByTag('makeUI')\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "makeUI"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93da37920ee14a3d9457faaecb334928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Choose from preset options:', layout=Layout(width='15%')), Dropdown(layout=Layout(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "  \n",
    "presets_input = widgets.Dropdown(options=[\" \",\"Weekly Lane Truckloads\", \"Weekly Store Sku Sales\"])\n",
    "\n",
    "def restore_version(self):\n",
    "    if presets_input.value == \"Weekly Lane Truckloads\":\n",
    "        #\"Weekly Lane Truckloads\", \"Weekly Store Sku Sales\"\n",
    "        timePeriod_input.value = 'FSCL_WK_END_DT'\n",
    "        hierarchy_input.value = 'origin, destin'\n",
    "        historicValue_input.value = 'loads'\n",
    "        snapshotPeriods_input.value = '3'\n",
    "        dataset_input.value = 'analytics-supplychain-thd.one_forecast_truck'\n",
    "        outputTable_input.value = 'one_forecast_truck'\n",
    "        forecastPeriodStart_input.value = datetime.date(2019, 1, 1)\n",
    "        forecastPeriodEnd_input.value = datetime.date(2019, 12, 31)\n",
    "        bucketPath_input.value = 'gs://sca-udf/reinforcejs-master/lib'\n",
    "        rawData_input.value = '`analytics-supplychain-thd.one_forecast_truck.inputs`'\n",
    "    elif presets_input.value == \"Weekly Store Sku Sales\":\n",
    "        timePeriod_input.value = 'FSCL_WK_END_DT'\n",
    "        hierarchy_input.value = 'str_nbr, sku_nbr'\n",
    "        historicValue_input.value = 'gross_unt_sls'\n",
    "        snapshotPeriods_input.value = '1'\n",
    "        dataset_input.value = 'analytics-supplychain-thd.one_forecast'\n",
    "        forecastPeriodStart_input.value = datetime.date(2019, 2, 4)\n",
    "        forecastPeriodEnd_input.value = datetime.date(2020, 2, 2)\n",
    "        bucketPath_input.value = 'gs://sca-udf/reinforcejs-master/lib'\n",
    "        rawData_input.value = '`analytics-supplychain-thd.one_forecast.str_sku_weekly_D28_C10`'\n",
    "\n",
    "presets_input.observe(restore_version)\n",
    "\n",
    "\n",
    "display_with_description(presets_input, 'Choose from preset options:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast Creation Input:\n",
    "Create up to three forecasts based on time series input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false,
    "tags": [
     "makeUI"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3a7f986a8254b6a911a078dc6a7bcdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Input Table Date Column:', layout=Layout(width='15%')), Dropdown(layout=Layout(wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "028881f2441e4c4a84c64f71a2063d08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Forecast Value Hierarchy:', layout=Layout(width='15%')), Text(value='', layout=Lay…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a468370229043de849d8579c094851f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Forecast Value:', layout=Layout(width='15%')), Text(value='', layout=Layout(width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4886f570fbf94381b2e3821190b3f068",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Forecast Periods:', layout=Layout(width='15%')), Text(value='', layout=Layout(widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1564b32d193d46d5b9edbc73c83fb8f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Output Dataset:', layout=Layout(width='15%')), Text(value='', layout=Layout(width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12c77b1ee8ff4b94a6a520a57e35183c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Final Output Table:', layout=Layout(width='15%')), Text(value='', layout=Layout(wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07967b22cf3e4a6b9da01b43008e8cbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Forecast Snapshot Start:', layout=Layout(width='15%')), DatePicker(value=None, lay…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8575a40aaa324b4ba1727f162fd8b2f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Forecast Snapshot End:', layout=Layout(width='15%')), DatePicker(value=None, layou…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1b294788636447f9fef611e415ebb60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Forecast Frequency:', layout=Layout(width='15%')), Dropdown(layout=Layout(width='8…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "971c36a3b35a42f1aa71f5e48bb3d954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Input Data Table:', layout=Layout(width='15%')), Text(value='', layout=Layout(widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f8f0495d6e47b283bef503b74fc77f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Checkbox(value=False, description='Round Output Values'), Checkbox(value=False, description='Di…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50fe026d35864d9ba664a5180dbd38a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Create Forecast', icon='upload', layout=Layout(width='100%'), styl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5a1369ecc004f4cba6fa6e887dcb6de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(button_style='primary', description='Clear Output', icon='trash', layout=Layout(width='1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa451070ce8245d39afa56819da4bb5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border='1px solid black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "$('.thd_cancel_button').click(function() {Jupyter.notebook.kernel.interrupt()\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#timePeriod_input = widgets.Text(placeholder='Name of date column in input table', save_id='timePeriod_input')\n",
    "timePeriod_input = widgets.Dropdown(options=[\" \",\"CAL_DT\", \"FSCL_WK_END_DT\"], save_id = 'timePeriod_input')\n",
    "hierarchy_input = widgets.Text(placeholder='List of column names to aggregate forecast at (ex: dept, class, subclass or origin, destination)', save_id='hierarchy_input')\n",
    "historicValue_input = widgets.Text(placeholder='Column name of target value to forecast', save_id='historicValue_input')\n",
    "snapshotPeriods_input = widgets.Text(placeholder='Number of periods to forecast from each forecast snapshot', save_id='snapshotPeriods_input')\n",
    "dataset_input = widgets.Text(placeholder='Dataset to output forecast to (ex: analytics-supplychain-thd.one_forecast)', save_id='dataset_input')\n",
    "outputTable_input = widgets.Text(placeholder='Table to ouput forecast to (ex: one_forecast)', save_id='dataset_input')\n",
    "forecastPeriodStart_input = widgets.DatePicker(save_id='forecastPeriodStart_input')\n",
    "forecastPeriodEnd_input = widgets.DatePicker(save_id='forecastPeriodEnd_input')\n",
    "rawData_input = widgets.Text(placeholder='Input Data Table (ex: analytics-supplychain-thd.one_forecast.inputs)', save_id='rawData_input')\n",
    "frequency_input = widgets.Dropdown(options=[\"Week\",\"Day\"])\n",
    "run_btn = widgets.Button(description='Create Forecast', icon='upload', layout=widgets.Layout(width='100%'), button_style='success')\n",
    "\n",
    "clear_btn = widgets.Button(description='Clear Output', icon='trash', layout=widgets.Layout(width='100%'), button_style='primary')\n",
    "cancel_btn = widgets.Button(description='Cancel Run', icon='ban', layout=widgets.Layout(width='100%'), button_style='danger').add_class('thd_cancel_button')\n",
    "\n",
    "out = widgets.Output(layout={'border': '1px solid black'})\n",
    "tempOut = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "round_box = widgets.Checkbox(value=False,description='Round Output Values',disabled=False)\n",
    "negative_box = widgets.Checkbox(value=False,description='Disallow Negative Output Values',disabled=False)\n",
    "\n",
    "\n",
    "#create forecast with current inputs\n",
    "def createForecast(self):\n",
    "    try:\n",
    "        outputCode['createForecast'] = '/******************************** Create Forecast ********************************/\\n'\n",
    "        timePeriod = timePeriod_input.value#one column date, can be any frequency daily and up\n",
    "        global hierarchyColumns\n",
    "        hierarchyColumns = hierarchy_input.value.split(',')#save column names to deaggregate later\n",
    "        for i in range(len(hierarchyColumns)):\n",
    "            hierarchyColumns[i] = hierarchyColumns[i].strip()\n",
    "        hierarchy = hierarchyColumns.copy()\n",
    "        for i in range(len(hierarchy)):\n",
    "            hierarchy[i] = 'cast(' + hierarchy[i] + ' as string)'\n",
    "        forecastValue = historicValue_input.value#one int or float column, target value to forecast\n",
    "        snapshotPeriods = snapshotPeriods_input.value#number of weeks to forecast\n",
    "        dataset = dataset_input.value.replace('`','')#dataset to store forecast in\n",
    "        forecastPeriodStart = forecastPeriodStart_input.value\n",
    "        forecastPeriodEnd = forecastPeriodEnd_input.value\n",
    "        transform1 = ''\n",
    "        transform2 = ''\n",
    "        if round_box.value:\n",
    "            if negative_box.value:\n",
    "                transform1 = 'round(greatest('\n",
    "                transform2 = ',0))'\n",
    "            else:\n",
    "                transform1 = 'round('\n",
    "                transform2 = ')'\n",
    "        elif negative_box.value:\n",
    "            transform1 = 'greatest('\n",
    "            transform2 = ',0)'\n",
    "        frequency = frequency_input.value#day, week or month\n",
    "        JSCloudPath = bucketPath_input.value\n",
    "        inputTable = rawData_input.value.replace('`','')\n",
    "        hierarchyString = ''', '|', '''.join(hierarchy)\n",
    "        outputTable = outputTable_input.value.replace('`', '').split('.')[-1]\n",
    "\n",
    "        global replaceDict\n",
    "        replaceDict = {'genericTimePeriod':timePeriod, 'genericHierarchy':hierarchyString, 'genericForecastValue':forecastValue\n",
    "                      ,'snapshotPeriods': snapshotPeriods, 'genericDataset': dataset#,'startYear' : startYear, 'endYear' : endYear\n",
    "                      ,'forecastPeriodStart': forecastPeriodStart, 'forecastPeriodEnd': forecastPeriodEnd, 'genericFrequency':frequency\n",
    "                      , 'genericInputTable': inputTable, 'plusOneSnapshotPeriods': str(int(snapshotPeriods) + 1), 'genericOutputTable' : outputTable}\n",
    "\n",
    "\n",
    "        if frequency.lower() == 'day':\n",
    "            replaceDict['genericSeasonality'] = \"[STRUCT('DAILY' AS TYPE, DAILY_SEASON AS SEASON, DAILY_HOLIDAY_FLG AS HOLIDAY_FLG), STRUCT('WEEKLY' AS TYPE, WEEKLY_SEASON AS SEASON, WEEKLY_HOLIDAY_FLG AS HOLIDAY_FLG)]\"\n",
    "            replaceDict['genericNumPeriods'] = 364 #currently this must be even\n",
    "            replaceDict['genericCalendarColumn'] = 'CAL_DT'\n",
    "            seasonal_config = [[\"'DAILY'\", 1], [\"'WEEKLY'\", 5]]\n",
    "        elif frequency.lower() == 'week':\n",
    "            replaceDict['genericSeasonality'] = \"[STRUCT('WEEKLY' AS TYPE, WEEKLY_SEASON AS SEASON, WEEKLY_HOLIDAY_FLG AS HOLIDAY_FLG)]\"\n",
    "            replaceDict['genericNumPeriods'] = 52\n",
    "            replaceDict['genericCalendarColumn'] = 'FSCL_WK_END_DT'\n",
    "            seasonal_config = [[\"'WEEKLY'\", 5]]\n",
    "        else:\n",
    "            replaceDict['genericSeasonality'] = \"[STRUCT('MONTHLY' AS TYPE, MONTHLY_SEASON AS SEASON, FALSE AS HOLIDAY_FLG)]\"\n",
    "            replaceDict['genericNumPeriods'] = 12\n",
    "            replaceDict['genericCalendarColumn'] = 'FSCL_PRD_END_DT'\n",
    "            seasonal_config = [[\"'MONTHLY'\", 3]]\n",
    "        replaceDict['genericSeasonalLags'] = max(x[1] for x in seasonal_config)\n",
    "        replaceDict['genericSeasonalUnion'] = ' UNION ALL '.join(['SELECT {} AS TYPE, {} AS LAGS'.format(x[0], x[1]) for x in seasonal_config])\n",
    "        replaceDict['genericTableOptionList'] = 'OPTIONS(EXPIRATION_TIMESTAMP=TIMESTAMP_ADD(CURRENT_TIMESTAMP, INTERVAL 1 DAY))'\n",
    "\n",
    "\n",
    "        if '' in replaceDict.values():\n",
    "            with out:\n",
    "                print(datetime.datetime.now().strftime('%H:%M:%S'), 'Error: missing input detected')\n",
    "            return\n",
    "        replaceDict['forecastTransform1'] = transform1\n",
    "        replaceDict['forecastTransform2'] = transform2\n",
    "        with out:\n",
    "            print(datetime.datetime.now().strftime('%H:%M:%S'), 'Creating forecast...')\n",
    "            print(genericReplace('Forecast(s) will be stored in `genericDataset.genericOutputTable`...',replaceDict))\n",
    "\n",
    "        replaceDict['genericTableOptionList'] = 'OPTIONS(EXPIRATION_TIMESTAMP=TIMESTAMP_ADD(CURRENT_TIMESTAMP, INTERVAL 1 DAY))'\n",
    "        exec_sql(\n",
    "           'create or replace table `genericDataset.raw_forecast_data` genericTableOptionList as ( select * from `'\n",
    "             + inputTable\n",
    "             + '`);',\n",
    "        replaceDict, 'createForecast')\n",
    "\n",
    "\n",
    "        with tempOut:\n",
    "            %store replaceDict\n",
    "\n",
    "        display(Javascript(\"execCellsByTag('Forecast1')\"))\n",
    "    except:\n",
    "        with out:\n",
    "            print(datetime.datetime.now().strftime('%H:%M:%S'), 'Error: Invalid input data detected. Please verify query and try again.')\n",
    "    \n",
    "    \n",
    "#clear all outputs\n",
    "def clearOutput(self):\n",
    "    out.clear_output()\n",
    "    insertOut.clear_output()\n",
    "    selectionOut.clear_output()\n",
    "    adjustOut.clear_output()\n",
    "    exportOut.clear_output()\n",
    "    \n",
    "\n",
    "\n",
    "display_with_description(timePeriod_input, 'Input Table Date Column:')\n",
    "display_with_description(hierarchy_input, 'Forecast Value Hierarchy:')\n",
    "display_with_description(historicValue_input, 'Forecast Value:')\n",
    "display_with_description(snapshotPeriods_input, 'Forecast Periods:')\n",
    "display_with_description(dataset_input, 'Output Dataset:')\n",
    "display_with_description(outputTable_input, 'Final Output Table:')\n",
    "display_with_description(forecastPeriodStart_input, 'Forecast Snapshot Start:')\n",
    "display_with_description(forecastPeriodEnd_input, 'Forecast Snapshot End:')\n",
    "display_with_description(frequency_input, 'Forecast Frequency:')\n",
    "display_with_description(rawData_input, 'Input Data Table:')\n",
    "display(widgets.HBox([round_box, negative_box]))\n",
    "\n",
    "display(run_btn)\n",
    "display(widgets.HBox([clear_btn, cancel_btn]))\n",
    "display(out)\n",
    "\n",
    "run_btn.on_click(createForecast)\n",
    "clear_btn.on_click(clearOutput)\n",
    "display(Javascript('''\n",
    "$('.thd_cancel_button').click(function() {Jupyter.notebook.kernel.interrupt()\n",
    "    }\n",
    ")\n",
    "'''))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## External Forecast Input (Optional):\n",
    "Add an external forecast to the one forecast table to be considered during the ensemble approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testString = \"`analytics-supplychain-thd.one_forecast_daily_test.one_forecast_test\"\n",
    "test = testString.replace('`', '').split('.')[-1]\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "makeUI"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70faf196a5614a5d8f8ea0235a11388f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Forecast Value Hierarchy:', layout=Layout(width='15%')), Text(value='', layout=Lay…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "035b88595036484c9600efc3d07df70b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='One Forecast Engine Table:', layout=Layout(width='15%')), Text(value='', layout=La…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd9bfe53c50547ab9fde62b3b48ac8b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Forecast Created Time Period:', layout=Layout(width='15%')), Text(value='', layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1e44d0f147445219a0faec4e6777d6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Forecast Time Period:', layout=Layout(width='15%')), Text(value='', layout=Layout(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83a52824b1094ed6835d9f190e0d68c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Forecast Value:', layout=Layout(width='15%')), Text(value='', layout=Layout(width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c2a68982e1d43f1a71a33caec4b8b61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Forecast Input Query:', layout=Layout(width='15%')), Textarea(value='', layout=Lay…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e54d93386b5e4a5db4f608bd1d219f34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Insert Additional Forecast', icon='upload', layout=Layout(width='1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a829bcfbc1ed46ba82b0de7bfee1cafc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border='1px solid black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def extractColumnNames(client, table):\n",
    "    project = table.split('.')[0]\n",
    "    dataset_id = table.split('.')[1]\n",
    "    table_id = table.split('.')[2]\n",
    "\n",
    "    dataset_ref = client.dataset(dataset_id, project=project)\n",
    "    table_ref = dataset_ref.table(table_id)\n",
    "    table = client.get_table(table_ref)  # API Request\n",
    "    \n",
    "    snapshotTime = ''\n",
    "    fcstTime = ''\n",
    "    forecastValue = ''\n",
    "    \n",
    "    for field in table.schema:\n",
    "        if re.search('snpsht_.+',field.name.lower()):\n",
    "            snapshotTime = field.name\n",
    "        if re.search('fcst_.+',field.name.lower()):\n",
    "            fcstTime = field.name\n",
    "        if re.search('forecast4_.+',field.name.lower()):\n",
    "            forecastValue = field.name\n",
    "    return([snapshotTime, fcstTime, forecastValue])\n",
    "\n",
    "\n",
    "\n",
    "#Input outside forecast option\n",
    "fcstHierarchy_input = widgets.Text(placeholder='List of column names to aggregate forecast at (ex: dept, class, subclass or origin, destination)', save_id='fcstHierarchy_input')\n",
    "fcstInsertTable_input = widgets.Text(placeholder='Table to input forecast to (ex: analytics-supplychain-thd.one_forecast.one_forecast)', save_id='fcstDataset_input')\n",
    "snapshotTimePeriod_input = widgets.Text(placeholder='Name of create date column in input query', save_id='snapshotTimePeriod_input')\n",
    "fcstTimePeriod_input = widgets.Text(placeholder='Name of forecast date column in input query', save_id='fcstTimePeriod_input')\n",
    "forecastValue_input = widgets.Text(placeholder='Target value from forecast input', save_id='forecastValue_input')\n",
    "newForecast_input = widgets.Textarea(placeholder='External Forecast Query (Must have columns representing Forecast Create Time, Forecast Time and Forecast Value)', save_id='newForecast_input', layout = widgets.Layout(height = '120px'))\n",
    "upload_btn = widgets.Button(description='Insert Additional Forecast', icon='upload', layout=widgets.Layout(width='100%'), button_style='success')\n",
    "insertOut = widgets.Output(layout={'border': '1px solid black'})\n",
    "            \n",
    "\n",
    "#joins input forecast into one_forecast table as \"forecast4\"\n",
    "def insertForecast(self):\n",
    "    outputCode['insertForecast'] = '/******************************** Insert Forecast ********************************/\\n'\n",
    "    hierarchyString = ''', '|', '''.join(fcstHierarchy_input.value.split(','))\n",
    "    fcstInsertTable = fcstInsertTable_input.value.replace('`', '')\n",
    "    try:\n",
    "        insertReplaceDict = {'snpsht_genericTimePeriod':snapshotTimePeriod_input.value, 'fcst_genericTimePeriod':fcstTimePeriod_input.value\n",
    "                     ,'genericHierarchy':hierarchyString, 'newForecastValue':forecastValue_input.value\n",
    "                      ,'genericInsertTable': fcstInsertTable, 'genericForecastValue':extractColumnNames(client, fcstInsertTable)[2]\n",
    "                    ,'genericDataset': '.'.join(fcstInsertTable.split('.', 2)[:2])}\n",
    "        with insertOut:\n",
    "            print(datetime.datetime.now().strftime('%H:%M:%S'), genericReplace('Adding input forecast to genericInsertTable',insertReplaceDict))\n",
    "        exec_sql(\n",
    "            ''' CREATE OR REPLACE TABLE `genericDataset.externalForecast` as\n",
    "                (\n",
    "                with tbl1 as (\n",
    "                %s\n",
    "                )\n",
    "                select snpsht_genericTimePeriod, fcst_genericTimePeriod, newForecastValue, concat(genericHierarchy) as aggLevel\n",
    "                from tbl1\n",
    "                );\n",
    "                ''' % (newForecast_input.value)\n",
    "        ,insertReplaceDict, 'insertForecast')\n",
    "                \n",
    "        exec_sql(   \n",
    "                '''update `genericInsertTable` a\n",
    "                set a.genericForecastValue = b.newForecastValue\n",
    "                FROM `genericDataset.externalForecast` b\n",
    "                where a.%s = b.snpsht_genericTimePeriod\n",
    "                and a.%s = b.fcst_genericTimePeriod\n",
    "                and a.aggLevel = b.aggLevel;\n",
    "            ''' % (extractColumnNames(client, fcstInsertTable)[0], extractColumnNames(client, fcstInsertTable)[1])\n",
    "            ,insertReplaceDict, 'insertForecast')\n",
    "        with insertOut:\n",
    "            print(datetime.datetime.now().strftime('%H:%M:%S'), genericReplace('Forecast successfully added to genericInsertTable',insertReplaceDict))\n",
    "    except:\n",
    "        with insertOut:\n",
    "            print(datetime.datetime.now().strftime('%H:%M:%S'), 'Error: Invalid inputs detected. Please verify query and try again.')\n",
    "        return\n",
    "\n",
    "display_with_description(fcstHierarchy_input, 'Forecast Value Hierarchy:')\n",
    "display_with_description(fcstInsertTable_input, 'One Forecast Engine Table:')\n",
    "display_with_description(snapshotTimePeriod_input, 'Forecast Created Time Period:')\n",
    "display_with_description(fcstTimePeriod_input, 'Forecast Time Period:')\n",
    "display_with_description(forecastValue_input, 'Forecast Value:')\n",
    "\n",
    "display_with_description(newForecast_input, 'Forecast Input Query:')\n",
    "display(upload_btn)\n",
    "display(insertOut)\n",
    "\n",
    "upload_btn.on_click(insertForecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble:\n",
    "Combine previously made forecasts into the best possible forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "makeUI"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45548297105440c1887e37c841fffea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Forecast Selection Logic:', layout=Layout(width='15%')), Dropdown(layout=Layout(wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad62f2c5a64a4107a2cd77f895560fee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Cloud Storage Bucket Path:', layout=Layout(width='15%')), Text(value='', layout=La…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24de82eefea54a39967860247fb19be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Include External Forecast Input?', layout=Layout(width='15%')), Dropdown(layout=La…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "561e1df0047f4187bb2105b55f7bbb58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Run Forecast Ensemble', icon='upload', layout=Layout(width='100%')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ea75ad683e64279a861b4d7aff807fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border='1px solid black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bucketPath_input = widgets.Text(placeholder='Path to Cloud Storage Bucket (Only Required for Reinforcement Learning Selection Logic - default location: gs://sca-udf/reinforcejs-master/lib)', save_id='bucketPath_input')\n",
    "selection_input = widgets.Dropdown(options=[\"\",\"Reinforcement Learning Selection\",\"Rules Based Selection\"], save_id ='selection_input')\n",
    "\n",
    "forecast4_drop = widgets.Dropdown(options = [\"No\", \"Yes\"], save_id = 'forecast4_input')\n",
    "\n",
    "display_with_description(selection_input, 'Forecast Selection Logic:')\n",
    "\n",
    "selectionOut = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "#runs selected ensemble logic cell\n",
    "def runEnsemble(self):\n",
    "    try:\n",
    "        replaceDict\n",
    "    except:\n",
    "        %store -r replaceDict\n",
    "    global ensembleReplaceDict\n",
    "    ensembleReplaceDict = replaceDict.copy()\n",
    "    if forecast4_drop.value == 'Yes':\n",
    "        ensembleReplaceDict['forecast3'] = 'forecast4'\n",
    "    outputCode['ensemble'] = '/******************************** Selection Logic ********************************/\\n'\n",
    "    ensembleReplaceDict['JSCloudPath'] = bucketPath_input.value\n",
    "    if (selection_input.value == '' or (selection_input.value == \"Reinforcement Learning Selection\" and bucketPath_input.value == '')):\n",
    "        with selectionOut:\n",
    "            print(datetime.datetime.now().strftime('%H:%M:%S'), 'Error: Invalid input data query detected. Please verify query and try again.')\n",
    "        return\n",
    "    with selectionOut:\n",
    "        print(datetime.datetime.now().strftime('%H:%M:%S'), 'Creating Selection Logic Input Tables...')\n",
    "    display(Javascript(\"execCellsByTag('SelectionInput')\"))\n",
    "    with selectionOut:\n",
    "        print(datetime.datetime.now().strftime('%H:%M:%S'), genericReplace('Running chosen selection logic, results will be stored in `genericDataset.genericOutputTable`...',replaceDict))\n",
    "    if selection_input.value == \"Reinforcement Learning Selection\":\n",
    "        display(Javascript(\"execCellsByTag('RLSelection')\"))\n",
    "    elif selection_input.value == \"Rules Based Selection\":\n",
    "        display(Javascript(\"execCellsByTag('RulesSelection')\"))\n",
    "    elif selection_input.value == \"Logistic Regression Selection\":\n",
    "        display(Javascript(\"execCellsByTag('LogRegSelection')\"))\n",
    "\n",
    "        \n",
    "display_with_description(bucketPath_input, 'Cloud Storage Bucket Path:')\n",
    "display_with_description(forecast4_drop, 'Include External Forecast Input?')\n",
    "\n",
    "ensemble_btn = widgets.Button(description='Run Forecast Ensemble', icon='upload', layout=widgets.Layout(width='100%'), button_style='success')\n",
    "ensemble_btn.on_click(runEnsemble)\n",
    "display(ensemble_btn)\n",
    "\n",
    "display(selectionOut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast Analysis (Optional):\n",
    "Plot newly created forecasts and error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false,
    "tags": [
     "makeUI",
     "graphMAPE"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fa14b8d274542cd82b2e55a93342a96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Forecast Lag to Plot:', layout=Layout(width='15%')), Text(value='', layout=Layout(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b026c2864c64d139d9efe0a2fc747f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Plot Period Start:', layout=Layout(width='15%')), DatePicker(value=None, layout=La…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a62898d1b7264af5bb63287d8af31746",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Plot Period End:', layout=Layout(width='15%')), DatePicker(value=None, layout=Layo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a888b5cc0954c5c8e5cf215fb145efd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Plot Forecast MAPE', icon='signal', layout=Layout(width='100%'), s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAPE_btn = widgets.Button(description='Plot Forecast MAPE', icon='signal', layout=widgets.Layout(width='100%'), button_style='success')\n",
    "lagMeasured_input = widgets.Text(placeholder='Forecast Lag to Plot', save_id='lagMeasured_input')\n",
    "plotPeriodStart_input = widgets.DatePicker(placeholder='Plot Start Date', save_id='plotPeriodStart_input')\n",
    "plotPeriodEnd_input = widgets.DatePicker(placeholder='Plot End Date', save_id='plotPeriodEnd_input')\n",
    "\n",
    "display_with_description(lagMeasured_input, 'Forecast Lag to Plot:')\n",
    "display_with_description(plotPeriodStart_input, 'Plot Period Start:')\n",
    "display_with_description(plotPeriodEnd_input, 'Plot Period End:')\n",
    "plotPeriodStart_input.value = datetime.date.today() - relativedelta(years = 1)\n",
    "plotPeriodEnd_input.value = datetime.date.today()\n",
    "\n",
    "display(MAPE_btn)\n",
    "\n",
    "#plots designated time period vs overall forecast MAPE chart\n",
    "def graphMAPE(self):\n",
    "    try:\n",
    "        try:\n",
    "            replaceDict\n",
    "        except:\n",
    "            %store -r replaceDict\n",
    "        global plotReplaceDict\n",
    "        plotReplaceDict = replaceDict.copy()\n",
    "        plotReplaceDict['forecastLag'] = int(lagMeasured_input.value) - 1\n",
    "        plotReplaceDict['plotPeriodStart'] = str(plotPeriodStart_input.value)\n",
    "        plotReplaceDict['plotPeriodEnd'] = str(plotPeriodEnd_input.value)\n",
    "        display(Javascript(\"clearCellsByTag('graphMAPE')\"))\n",
    "        display_with_description(lagMeasured_input, 'Forecast Lag to Plot:')\n",
    "        display_with_description(plotPeriodStart_input, 'Plot Period Start:')\n",
    "        display_with_description(plotPeriodEnd_input, 'Plot Period End:')\n",
    "        display(MAPE_btn)\n",
    "        df = pd.read_gbq(genericReplace('''SELECT snpsht_genericTimePeriod as snpsht_time, fcst_genericTimePeriod as fcst_time\n",
    "        , safe_divide(sum(abs(forecast1_genericForecastValue - actual_genericForecastValue)),sum(actual_genericForecastValue)) forecast1_MAPE\n",
    "        , safe_divide(sum(abs(forecast2_genericForecastValue - actual_genericForecastValue)),sum(actual_genericForecastValue)) forecast2_MAPE\n",
    "        , safe_divide(sum(abs(forecast3_genericForecastValue - actual_genericForecastValue)),sum(actual_genericForecastValue)) forecast3_MAPE\n",
    "        , safe_divide(sum(abs(forecast4_genericForecastValue - actual_genericForecastValue)),sum(actual_genericForecastValue)) forecast4_MAPE\n",
    "        , safe_divide(sum(abs(one_forecast_genericForecastValue - actual_genericForecastValue)),sum(actual_genericForecastValue)) one_forecast_MAPE\n",
    "        FROM `genericDataset.genericOutputTable`\n",
    "        where DATE_DIFF(fcst_genericTimePeriod, snpsht_genericTimePeriod,genericFrequency) = forecastLag\n",
    "        and actual_genericForecastValue is not null\n",
    "        --and actual_genericForecastValue > 0\n",
    "        and fcst_genericTimePeriod between 'plotPeriodStart' and 'plotPeriodEnd'\n",
    "        group by 1,2\n",
    "        order by 1,2''',plotReplaceDict)\n",
    "            , dialect='standard'\n",
    "            ,configuration = {'query': {'useQueryCache': False}})\n",
    "\n",
    "        plt.axes(xlabel = 'Date', ylabel = 'MAPE', title = 'Forecast MAPE')\n",
    "        forecast1, = plt.plot(df.fcst_time, df.forecast1_MAPE,label = 'Forecast 1')\n",
    "        forecast2, = plt.plot(df.fcst_time, df.forecast2_MAPE,label = 'Forecast 2')\n",
    "        forecast3, = plt.plot(df.fcst_time, df.forecast3_MAPE,label = 'Forecast 3')\n",
    "        forecast4, = plt.plot(df.fcst_time, df.forecast4_MAPE,label = 'Forecast 4')\n",
    "        one_forecast, = plt.plot(df.fcst_time, df.one_forecast_MAPE,label = 'One Forecast')\n",
    "        plt.legend(handles=[forecast1, forecast2, forecast3, forecast4, one_forecast])\n",
    "        matplotlib.rcParams['figure.figsize'] = [24,9]\n",
    "        matplotlib.rcParams['figure.dpi'] = 80\n",
    "\n",
    "        plt.show()\n",
    "    except:\n",
    "        print(datetime.datetime.now().strftime('%H:%M:%S'), 'Error: Invalid input data query detected. Please verify query and try again. Note that a forecast must have been created in the current session to be plotted.')\n",
    "    \n",
    "\n",
    "\n",
    "MAPE_btn.on_click(graphMAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false,
    "tags": [
     "makeUI",
     "graphForecast"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1807cf3ff3c495095e45f8d4afbf82a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Plot Forecasts', icon='signal', layout=Layout(width='100%'), style…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph_btn = widgets.Button(description='Plot Forecasts', icon='signal', layout=widgets.Layout(width='100%'), button_style='success')\n",
    "display(graph_btn)\n",
    "\n",
    "#plot forecasts vs actuals\n",
    "def graphForecasts(self):\n",
    "    try:\n",
    "        try:\n",
    "            replaceDict\n",
    "        except:\n",
    "            %store -r replaceDict\n",
    "        global plotReplaceDict\n",
    "        plotReplaceDict = replaceDict.copy()\n",
    "        plotReplaceDict['forecastLag'] = int(lagMeasured_input.value) - 1\n",
    "        plotReplaceDict['plotPeriodStart'] = str(plotPeriodStart_input.value)\n",
    "        plotReplaceDict['plotPeriodEnd'] = str(plotPeriodEnd_input.value)\n",
    "        display(Javascript(\"clearCellsByTag('graphForecast')\"))\n",
    "        display(graph_btn)\n",
    "        df = pd.read_gbq(genericReplace('''SELECT snpsht_genericTimePeriod as snpsht_time, fcst_genericTimePeriod as fcst_time\n",
    "        , sum(forecast1_genericForecastValue) as forecast1_value\n",
    "        , sum(forecast2_genericForecastValue) as forecast2_value\n",
    "        , sum(forecast3_genericForecastValue) as forecast3_value\n",
    "        , sum(forecast4_genericForecastValue) as forecast4_value\n",
    "        , sum(one_forecast_genericForecastValue) as one_forecast_value\n",
    "        , sum(actual_genericForecastValue) as actual_value\n",
    "        FROM `genericDataset.genericOutputTable`\n",
    "        where DATE_DIFF(fcst_genericTimePeriod, snpsht_genericTimePeriod,genericFrequency) = forecastLag\n",
    "        and actual_genericForecastValue is not null\n",
    "        and fcst_genericTimePeriod between 'plotPeriodStart' and 'plotPeriodEnd'\n",
    "        group by 1,2\n",
    "        order by 1,2''',plotReplaceDict)\n",
    "            , dialect='standard'\n",
    "            ,configuration = {'query': {'useQueryCache': False}})\n",
    "\n",
    "        plt.axes(xlabel = 'Date', ylabel = genericReplace('genericForecastValue', replaceDict), title = 'Forecast vs Actuals')\n",
    "        forecast1, = plt.plot(df.fcst_time, df.forecast1_value,label = 'Forecast 1')\n",
    "        forecast2, = plt.plot(df.fcst_time, df.forecast2_value,label = 'Forecast 2')\n",
    "        forecast3, = plt.plot(df.fcst_time, df.forecast3_value,label = 'Forecast 3')\n",
    "        forecast4, = plt.plot(df.fcst_time, df.forecast4_value,label = 'Forecast 4')\n",
    "        one_forecast, = plt.plot(df.fcst_time, df.one_forecast_value,label = 'one_forecast')\n",
    "        actuals, = plt.plot(df.fcst_time, df.actual_value,label = 'Actuals')\n",
    "        plt.legend(handles=[forecast1, forecast2, forecast3, forecast4, one_forecast, actuals])\n",
    "\n",
    "        matplotlib.rcParams['figure.figsize'] = [24,9]\n",
    "        matplotlib.rcParams['figure.dpi'] = 80\n",
    "        plt.show()\n",
    "    except:\n",
    "        print(datetime.datetime.now().strftime('%H:%M:%S'), 'Error: Invalid input data query detected. Please verify query and try again. Note that a forecast must have been created in the current session to be plotted.')\n",
    "    \n",
    "graph_btn.on_click(graphForecasts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast Adjustments (Optional):\n",
    "Make adjustments to the recently created forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "makeUI"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fd5023ec5384117a9519f746737d334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Forecast Adjustment Options', layout=Layout(width='15%')), Dropdown(layout=Layout(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b77f425f9bd4d789aacc4274c9e2541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Adjustment Percentage', layout=Layout(width='15%')), Text(value='', layout=Layout(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f053092741fe43c6b7ab4abe37cefa89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Adjust Forecast', icon='gear', layout=Layout(width='100%'), style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f6ec1e17289464da22beccf100031d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border='1px solid black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "forecastAdjustment = widgets.Dropdown(options=[\"\", \"Reactive Adjustments - Adjust to consistent over/underforecasting over last 3 periods\"\n",
    "                                               ,\"Forecast Increase - Across the board increase in forecast values by x%\"\n",
    "                                              ,\"Forecast Decrease - Across the board decrease in forecast values by x%\"])\n",
    "adjustPeriods_input = widgets.Text(placeholder='Number of periods to adjust off of (n)', save_id='adjustPeriods_input')\n",
    "adjustPercent_input = widgets.Text(placeholder='% forecast adjustment (x)', save_id='adjustPercent_input')\n",
    "adjust_btn = widgets.Button(description='Adjust Forecast', icon='gear', layout=widgets.Layout(width='100%'), button_style='success')\n",
    "adjustOut = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "\n",
    "display_with_description(forecastAdjustment, \"Forecast Adjustment Options\")\n",
    "#display_with_description(adjustPeriods_input, \"Adjustment Periods\")\n",
    "display_with_description(adjustPercent_input, \"Adjustment Percentage\")\n",
    "display(adjust_btn)\n",
    "display(adjustOut)\n",
    "    \n",
    "#adjust forecasts based on selected inputs\n",
    "def adjustForecast(self):\n",
    "    outputCode['adjustments'] = '/******************************** Forecast Adjustments ********************************/\\n'\n",
    "    try:\n",
    "        try:\n",
    "            replaceDict\n",
    "        except:\n",
    "            %store -r replaceDict\n",
    "        with adjustOut:\n",
    "            print(datetime.datetime.now().strftime('%H:%M:%S'), genericReplace('Forecasts stored in `genericDataset.genericOutputTable` will be adjusted accordingly...', replaceDict))\n",
    "        replaceDict['adjustPercent'] = adjustPercent_input.value\n",
    "        replaceDict['adjustPeriods'] = adjustPeriods_input.value\n",
    "        if forecastAdjustment.value == \"Reactive Adjustments - Adjust to consistent over/underforecasting over last 3 periods\":\n",
    "            exec_sql(\n",
    "            '''\n",
    "            create temp function MAPE_adjust(forecasts ARRAY<STRUCT<fcst_genericTimePeriod date, forecast1_genericForecastValue float64, forecast2_genericForecastValue float64\n",
    "                    , forecast3_genericForecastValue float64, forecast1_diff float64, forecast2_diff float64, forecast3_diff float64, actual_genericForecastValue float64>>)\n",
    "            RETURNS ARRAY<STRUCT<fcst_genericTimePeriod date, forecast1_genericForecastValue float64, adj_forecast1_genericForecastValue float64\n",
    "            , forecast2_genericForecastValue float64, adj_forecast2_genericForecastValue float64\n",
    "            , forecast3_genericForecastValue float64, adj_forecast3_genericForecastValue float64, actual_genericForecastValue float64>>\n",
    "            LANGUAGE js as \"\"\"\n",
    "\n",
    "              var data = forecasts.map(function(obj) {\n",
    "                return Object.keys(obj).map(function(key) {\n",
    "                  return obj[key]\n",
    "                })\n",
    "              })\n",
    "\n",
    "\n",
    "              var week = []\n",
    "              var unadjusted_vals = []\n",
    "              var adjusted_vals = []\n",
    "              var diffs = []\n",
    "              var i = 0\n",
    "              while(i < data.length) {\n",
    "                  week.push(data[i][0])\n",
    "                  unadjusted_vals.push(data[i].slice(1,4))\n",
    "                  adjusted_vals.push(data[i].slice(1,4))\n",
    "                  diffs.push(data[i].slice(4,7))\n",
    "                  i++\n",
    "              }\n",
    "\n",
    "              var wk = 0\n",
    "              var output = []\n",
    "              var trendWeeks = 3\n",
    "              while(wk < week.length) {\n",
    "                var fcst = 0\n",
    "                while (fcst < unadjusted_vals.length - 1 && wk >= trendWeeks) {\n",
    "                  if ((diffs[wk-1][fcst] < 0 && diffs[wk-2][fcst] < 0 && diffs[wk-3][fcst] < 0) || (diffs[wk-1][fcst] > 0 && diffs[wk-2][fcst] > 0 && diffs[wk-3][fcst] > 0)) {\n",
    "                      var avgDiff = (diffs[wk-1][fcst] + diffs[wk-2][fcst] + diffs[wk-3][fcst])/3\n",
    "                      if (unadjusted_vals[wk][fcst] - avgDiff > 0) {\n",
    "                          adjusted_vals[wk][fcst] = unadjusted_vals[wk][fcst] - avgDiff\n",
    "                      } else {\n",
    "                          adjusted_vals[wk][fcst] = 0\n",
    "                      }\n",
    "                  }\n",
    "                  fcst++\n",
    "                }\n",
    "                output.push({fcst_genericTimePeriod:week[wk], adj_forecast1_genericForecastValue:Math.round(adjusted_vals[wk][0]), adj_forecast2_genericForecastValue:Math.round(adjusted_vals[wk][1])\n",
    "                , adj_forecast3_genericForecastValue:Math.round(adjusted_vals[wk][2]), forecast1_genericForecastValue:unadjusted_vals[wk][0], forecast2_genericForecastValue:unadjusted_vals[wk][1]\n",
    "                , forecast3_genericForecastValue:unadjusted_vals[wk][2], actual_genericForecastValue:data[wk][7]})\n",
    "                wk++\n",
    "              }\n",
    "\n",
    "              return output\n",
    "\n",
    "\n",
    "            \"\"\"\n",
    "            OPTIONS ();\n",
    "\n",
    "            update `genericDataset.genericOutputTable` a\n",
    "            set\n",
    "            a.forecast1_genericForecastValue = b.adj_forecast1_genericForecastValue\n",
    "            ,a.forecast2_genericForecastValue = b.adj_forecast2_genericForecastValue\n",
    "            ,a.forecast3_genericForecastValue = b.adj_forecast3_genericForecastValue\n",
    "            from\n",
    "            (select \n",
    "            aggLevel, b.* from\n",
    "            (select aggLevel,\n",
    "            MAPE_adjust(ARRAY_AGG(STRUCT( fcst_genericTimePeriod , forecast1_genericForecastValue, forecast2_genericForecastValue, forecast3_genericForecastValue\n",
    "            , forecast1_diff, forecast2_diff, forecast3_diff, coalesce(actual_genericForecastValue,0) as actual_genericForecastValue)\n",
    "                                  order by fcst_genericTimePeriod )) as adj_forecasts\n",
    "            from\n",
    "            (select SNPSHT_genericTimePeriod , fcst_genericTimePeriod , aggLevel, forecast1_genericForecastValue,forecast2_genericForecastValue,forecast3_genericForecastValue, actual_genericForecastValue\n",
    "            , forecast1_genericForecastValue - actual_genericForecastValue as forecast1_diff\n",
    "            , forecast2_genericForecastValue - actual_genericForecastValue as forecast2_diff\n",
    "            , forecast3_genericForecastValue - actual_genericForecastValue as forecast3_diff\n",
    "            from `genericDataset.genericOutputTable`\n",
    "            where ( SNPSHT_genericTimePeriod = fcst_genericTimePeriod\n",
    "            and fcst_genericTimePeriod >= CAST(cast('forecastPeriodStart' as string) as date)\n",
    "            and fcst_genericTimePeriod <= CAST(cast('forecastPeriodEnd' as string) as date))\n",
    "            order by 1,2)\n",
    "            group by 1) a\n",
    "            ,unnest(adj_forecasts) b\n",
    "            ) b\n",
    "            where\n",
    "            a.aggLevel = b.aggLevel\n",
    "            and a.fcst_genericTimePeriod = b.fcst_genericTimePeriod\n",
    "            and a.snpsht_genericTimePeriod = a.fcst_genericTimePeriod;\n",
    "            ''',replaceDict, 'adjustments')\n",
    "            with adjustOut:\n",
    "                print(datetime.datetime.now().strftime('%H:%M:%S'), genericReplace('Forecasts in `genericDataset.genericOutputTable` adjusted based on preceding 3 genericFrequency periods.', replaceDict))\n",
    "        elif forecastAdjustment.value == \"Forecast Increase - Across the board increase in forecast values by x%\":\n",
    "            exec_sql('''update `genericDataset.genericOutputTable` a\n",
    "                    set a.forecast1_genericForecastValue = forecastTransform1 b.forecast1_genericForecastValue * (1 + abs(adjustPercent/100)) forecastTransform2\n",
    "                    ,a.forecast2_genericForecastValue = forecastTransform1 b.forecast2_genericForecastValue * (1 + abs(adjustPercent/100)) forecastTransform2\n",
    "                    ,a.forecast3_genericForecastValue = forecastTransform1 b.forecast3_genericForecastValue * (1 + abs(adjustPercent/100)) forecastTransform2\n",
    "                    ,a.forecast4_genericForecastValue = forecastTransform1 b.forecast4_genericForecastValue * (1 + abs(adjustPercent/100)) forecastTransform2\n",
    "                    from `genericDataset.genericOutputTable` b\n",
    "                    where a.snpsht_genericTimePeriod = b.snpsht_genericTimePeriod\n",
    "                    and a.fcst_genericTimePeriod = b.fcst_genericTimePeriod\n",
    "                    and a.aggLevel = b.aggLevel;\n",
    "                ''',replaceDict, 'adjustments')\n",
    "            with adjustOut:\n",
    "                print(datetime.datetime.now().strftime('%H:%M:%S'), genericReplace('Forecasts in `genericDataset.genericOutputTable` increased by adjustPercent%.', replaceDict))\n",
    "        elif forecastAdjustment.value == \"Forecast Decrease - Across the board decrease in forecast values by x%\":\n",
    "                exec_sql('''update `genericDataset.genericOutputTable` a\n",
    "                set a.forecast1_genericForecastValue = forecastTransform1 b.forecast1_genericForecastValue * (1 - abs(adjustPercent/100)) forecastTransform2\n",
    "                ,a.forecast2_genericForecastValue = forecastTransform1 b.forecast2_genericForecastValue * (1 - abs(adjustPercent/100)) forecastTransform2\n",
    "                ,a.forecast3_genericForecastValue = forecastTransform1 b.forecast3_genericForecastValue * (1 - abs(adjustPercent/100)) forecastTransform2\n",
    "                ,a.forecast4_genericForecastValue = forecastTransform1 b.forecast4_genericForecastValue * (1 - abs(adjustPercent/100)) forecastTransform2\n",
    "                from `genericDataset.genericOutputTable` b\n",
    "                where a.snpsht_genericTimePeriod = b.snpsht_genericTimePeriod\n",
    "                and a.fcst_genericTimePeriod = b.fcst_genericTimePeriod\n",
    "                and a.aggLevel = b.aggLevel;\n",
    "                ''',replaceDict, 'adjustments')\n",
    "                with adjustOut:\n",
    "                    print(datetime.datetime.now().strftime('%H:%M:%S'), genericReplace('Forecasts in `genericDataset.genericOutputTable` decreased by adjustPercent%.', replaceDict))\n",
    "        else:\n",
    "            with adjustOut:\n",
    "                print(datetime.datetime.now().strftime('%H:%M:%S'), 'Error: Invalid input detected while adjusting genericOutputTable table. Please verify inputs and try again.')\n",
    "\n",
    "    except:\n",
    "        with adjustOut:\n",
    "            print(datetime.datetime.now().strftime('%H:%M:%S'), 'Error: Invalid input detected while adjusting genericOutputTable table. Please verify inputs and try again.')\n",
    "            \n",
    "adjust_btn.on_click(adjustForecast)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Forecast:\n",
    "Download the most recently run forecast code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "makeUI"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb4bbff6225a411aa8e331fe532d8863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Export Forecast', icon='download', layout=Layout(width='100%'), st…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ea36513fd754b84a3f3c86589bb7a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border='1px solid black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "export_btn = widgets.Button(description='Export Forecast', icon='download', layout=widgets.Layout(width='100%'), button_style='success')\n",
    "exportOut = widgets.Output(layout={'border': '1px solid black'})\n",
    "\n",
    "#export previously run code to txt file in cwd\n",
    "def exportForecast(self):\n",
    "    text_file = open(\"output.txt\", \"w\")\n",
    "    text_file.write('{createForecast} \\n {insertForecast} \\n {adjustments} \\n {ensemble}'.format(**outputCode))\n",
    "    text_file.close()\n",
    "    with exportOut:\n",
    "        print(datetime.datetime.now().strftime('%H:%M:%S'), 'Most recent forecast run output to the output.txt file in the directory: %s' % (os.getcwd()))\n",
    "\n",
    "export_btn.on_click(exportForecast)\n",
    "display(export_btn)\n",
    "display(exportOut)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": [
     "Forecast1"
    ]
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    exec_sql(\n",
    "       '''\n",
    "            \n",
    "            create or replace table `genericDataset.forecast_data` genericTableOptionList as (\n",
    "            \n",
    "            with tbl1 as (\n",
    "            select a.*, coalesce(b.genericForecastValue,0) as genericForecastValue from\n",
    "            (select * from\n",
    "            (select distinct concat(genericHierarchy) as aggLevel from `genericDataset.raw_forecast_data`)\n",
    "            cross join\n",
    "            (select distinct genericTimePeriod from `genericDataset.raw_forecast_data`)) a\n",
    "            left join\n",
    "            (select *, concat(genericHierarchy) as aggLevel from `genericDataset.raw_forecast_data`) b\n",
    "            on a.aggLevel = b.aggLevel\n",
    "            and a.genericTimePeriod = b.genericTimePeriod\n",
    "\n",
    "            )\n",
    "\n",
    "            \n",
    "            select a.*, EXTRACT(DAYOFWEEK FROM genericTimePeriod) as dayofweek\n",
    "            from TBL1 a\n",
    "            ,\n",
    "            (select min(genericTimePeriod) start_date, concat(genericHierarchy) as aggLevel\n",
    "            from `genericDataset.raw_forecast_data`\n",
    "            where genericForecastValue > 0\n",
    "            group by 2) b\n",
    "            where genericTimePeriod >= start_date\n",
    "            and a.aggLevel = b.aggLevel\n",
    "            );\n",
    "            ''',replaceDict, 'createForecast')\n",
    "    \n",
    "    with out:\n",
    "        print(datetime.datetime.now().strftime('%H:%M:%S'), 'Forecast 1 step 1/5 completed...')\n",
    "    \n",
    "\n",
    "    exec_sql(\n",
    "    '''\n",
    "    create or replace table `genericDataset.forecast_periods` genericTableOptionList AS (\n",
    "    with periods as(\n",
    "    SELECT A.FCST_genericTimePeriod as SNPSHT_genericTimePeriod, C.genericTimePeriod as FCST_genericTimePeriod, B.EVAL_genericTimePeriod\n",
    "    , DATE_DIFF(A.fcst_genericTimePeriod\n",
    "    , date_add(B.eval_genericTimePeriod\n",
    "    , interval mod(greatest(date_diff(date_sub(a.fcst_genericTimePeriod, interval DATE_DIFF(A.fcst_genericTimePeriod, B.eval_genericTimePeriod,YEAR) YEAR), b.eval_genericTimePeriod,genericFrequency)\n",
    "    ,date_diff(date_sub(a.fcst_genericTimePeriod, interval DATE_DIFF(A.fcst_genericTimePeriod, B.eval_genericTimePeriod,YEAR) - 1 YEAR), b.eval_genericTimePeriod,genericFrequency)),52) genericFrequency) ,YEAR) AS YR\n",
    "    , mod(greatest(date_diff(date_sub(a.fcst_genericTimePeriod, interval DATE_DIFF(A.fcst_genericTimePeriod, B.eval_genericTimePeriod,YEAR) YEAR), b.eval_genericTimePeriod,genericFrequency)\n",
    "    ,date_diff(date_sub(a.fcst_genericTimePeriod, interval DATE_DIFF(A.fcst_genericTimePeriod, B.eval_genericTimePeriod,YEAR) - 1 YEAR), b.eval_genericTimePeriod,genericFrequency)), 52)\n",
    "    AS genericFrequency\n",
    "    FROM\n",
    "    (\n",
    "    SELECT DISTINCT RANK() OVER (ORDER BY genericTimePeriod) TIME_RANK, genericTimePeriod FCST_genericTimePeriod, FSCL_YR FROM `pr-edw-views-thd.SHARED.CAL_PRD_HIER_FD`\n",
    "    WHERE cal_dt BETWEEN (select min(genericTimePeriod) from `genericDataset.forecast_data`) and current_date()\n",
    "    and cal_dt = genericCalendarColumn\n",
    "    ORDER BY 1\n",
    "    ) A\n",
    "    INNER JOIN\n",
    "    (\n",
    "    SELECT DISTINCT RANK() OVER (ORDER BY genericTimePeriod) TIME_RANK, genericTimePeriod EVAL_genericTimePeriod FROM `pr-edw-views-thd.SHARED.CAL_PRD_HIER_FD`\n",
    "    WHERE cal_dt BETWEEN (select min(genericTimePeriod) from `genericDataset.forecast_data`) and (select max(genericTimePeriod) from `genericDataset.forecast_data`)\n",
    "    and cal_dt = genericCalendarColumn\n",
    "    ORDER BY 1\n",
    "    ) B\n",
    "    ON (date_diff(date_sub(a.fcst_genericTimePeriod, interval DATE_DIFF(A.fcst_genericTimePeriod, B.eval_genericTimePeriod,YEAR) YEAR), b.eval_genericTimePeriod,genericFrequency) BETWEEN 1 AND genericNumPeriods/4\n",
    "    or date_diff(date_sub(a.fcst_genericTimePeriod, interval DATE_DIFF(A.fcst_genericTimePeriod, B.eval_genericTimePeriod,YEAR) - 1 YEAR), b.eval_genericTimePeriod,genericFrequency) BETWEEN 1 AND genericNumPeriods/4)\n",
    "    INNER JOIN\n",
    "    (SELECT DISTINCT RANK() OVER (ORDER BY genericTimePeriod) TIME_RANK, genericTimePeriod FROM `pr-edw-views-thd.SHARED.CAL_PRD_HIER_FD`\n",
    "    WHERE cal_dt >= (select min(genericTimePeriod) from `genericDataset.forecast_data`)\n",
    "    and cal_dt = genericCalendarColumn\n",
    "    ORDER BY 1) C\n",
    "    ON date_diff(C.genericTimePeriod, A.fcst_genericTimePeriod, genericFrequency) BETWEEN 0 AND (snapshotPeriods - 1)\n",
    "    WHERE\n",
    "    a.fcst_genericTimePeriod in (SELECT distinct genericTimePeriod From `pr-edw-views-thd.SHARED.CAL_PRD_HIER_FD` where \n",
    "    CAST(cast('forecastPeriodStart' as string) as date) <= CAL_DT\n",
    "    and CAST(cast('forecastPeriodEnd' as string) as date) >= CAL_DT)\n",
    "    and A.TIME_RANK > B.TIME_RANK\n",
    "    and DATE_DIFF(A.fcst_genericTimePeriod, B.eval_genericTimePeriod,YEAR) <= 6#years of history to use\n",
    "    )\n",
    "    \n",
    "    select * from periods\n",
    "    where concat(cast(snpsht_genericTimePeriod as string), cast(fcst_genericTimePeriod as string), cast(yr as string)) in\n",
    "    (select concat(cast(snpsht_genericTimePeriod as string), cast(fcst_genericTimePeriod as string), cast(yr as string)) from periods\n",
    "    group by 1\n",
    "    having count(genericFrequency) = genericNumPeriods/4)\n",
    "    );\n",
    "    ''',replaceDict, 'createForecast'\n",
    "    ,altSQL='''create or replace table `genericDataset.forecast_periods` genericTableOptionList AS (\n",
    "    with periods as(\n",
    "    SELECT A.FCST_genericTimePeriod as SNPSHT_genericTimePeriod, C.genericTimePeriod as FCST_genericTimePeriod, B.EVAL_genericTimePeriod\n",
    "    , DATE_DIFF(A.fcst_genericTimePeriod\n",
    "    , date_add(B.eval_genericTimePeriod\n",
    "    , interval mod(greatest(date_diff(date_sub(a.fcst_genericTimePeriod, interval DATE_DIFF(A.fcst_genericTimePeriod, B.eval_genericTimePeriod,YEAR) YEAR), b.eval_genericTimePeriod,genericFrequency)\n",
    "    ,date_diff(date_sub(a.fcst_genericTimePeriod, interval DATE_DIFF(A.fcst_genericTimePeriod, B.eval_genericTimePeriod,YEAR) - 1 YEAR), b.eval_genericTimePeriod,genericFrequency)),52) genericFrequency) ,YEAR) AS YR\n",
    "    , mod(greatest(date_diff(date_sub(a.fcst_genericTimePeriod, interval DATE_DIFF(A.fcst_genericTimePeriod, B.eval_genericTimePeriod,YEAR) YEAR), b.eval_genericTimePeriod,genericFrequency)\n",
    "    ,date_diff(date_sub(a.fcst_genericTimePeriod, interval DATE_DIFF(A.fcst_genericTimePeriod, B.eval_genericTimePeriod,YEAR) - 1 YEAR), b.eval_genericTimePeriod,genericFrequency)), 52)\n",
    "    AS genericFrequency\n",
    "    FROM\n",
    "    (\n",
    "    SELECT DISTINCT RANK() OVER (ORDER BY genericTimePeriod) TIME_RANK, genericTimePeriod FCST_genericTimePeriod, FSCL_YR FROM `pr-edw-views-thd.SHARED.CAL_PRD_HIER_FD`\n",
    "    WHERE cal_dt BETWEEN (select min(genericTimePeriod) from `genericDataset.forecast_data`) and current_date()\n",
    "    and cal_dt = genericCalendarColumn\n",
    "    ORDER BY 1\n",
    "    ) A\n",
    "    INNER JOIN\n",
    "    (\n",
    "    SELECT DISTINCT RANK() OVER (ORDER BY genericTimePeriod) TIME_RANK, genericTimePeriod EVAL_genericTimePeriod FROM `pr-edw-views-thd.SHARED.CAL_PRD_HIER_FD`\n",
    "    WHERE cal_dt BETWEEN (select min(genericTimePeriod) from `genericDataset.forecast_data`) and (select max(genericTimePeriod) from `genericDataset.forecast_data`)\n",
    "    and cal_dt = genericCalendarColumn\n",
    "    ORDER BY 1\n",
    "    ) B\n",
    "    ON (date_diff(date_sub(a.fcst_genericTimePeriod, interval DATE_DIFF(A.fcst_genericTimePeriod, B.eval_genericTimePeriod,YEAR) YEAR), b.eval_genericTimePeriod,genericFrequency) BETWEEN 1 AND genericNumPeriods/4\n",
    "    or date_diff(date_sub(a.fcst_genericTimePeriod, interval DATE_DIFF(A.fcst_genericTimePeriod, B.eval_genericTimePeriod,YEAR) - 1 YEAR), b.eval_genericTimePeriod,genericFrequency) BETWEEN 1 AND genericNumPeriods/4)\n",
    "    INNER JOIN\n",
    "    (SELECT DISTINCT RANK() OVER (ORDER BY genericTimePeriod) TIME_RANK, genericTimePeriod FROM `pr-edw-views-thd.SHARED.CAL_PRD_HIER_FD`\n",
    "    WHERE cal_dt >= (select min(genericTimePeriod) from `genericDataset.forecast_data`)\n",
    "    and cal_dt = genericCalendarColumn\n",
    "    ORDER BY 1) C\n",
    "    ON date_diff(C.genericTimePeriod, A.fcst_genericTimePeriod, genericFrequency) BETWEEN 0 AND (snapshotPeriods - 1)\n",
    "    WHERE\n",
    "    a.fcst_genericTimePeriod in (SELECT distinct genericTimePeriod From `pr-edw-views-thd.SHARED.CAL_PRD_HIER_FD` where \n",
    "    date_trunc(current_date(), genericFrequency) <= CAL_DT\n",
    "    and date_trunc(current_date(), genericFrequency) >= CAL_DT)\n",
    "    and A.TIME_RANK > B.TIME_RANK\n",
    "    and DATE_DIFF(A.fcst_genericTimePeriod, B.eval_genericTimePeriod,YEAR) <= 6#years of history to use\n",
    "    )\n",
    "    \n",
    "    select * from periods\n",
    "    where concat(cast(snpsht_genericTimePeriod as string), cast(fcst_genericTimePeriod as string), cast(yr as string)) in\n",
    "    (select concat(cast(snpsht_genericTimePeriod as string), cast(fcst_genericTimePeriod as string), cast(yr as string)) from periods\n",
    "    group by 1\n",
    "    having count(genericFrequency) = genericNumPeriods/4)\n",
    "    );''')\n",
    "\n",
    "    with out:\n",
    "        print(datetime.datetime.now().strftime('%H:%M:%S'), 'Forecast 1 step 2/5 completed...')\n",
    "\n",
    "    exec_sql(\n",
    "    '''\n",
    "    create or replace table `genericDataset.forecast_samples` genericTableOptionList AS (\n",
    "    SELECT\n",
    "            snpsht_genericTimePeriod\n",
    "            , fcst_genericTimePeriod\n",
    "            , genericTimePeriod\n",
    "            , aggLevel\n",
    "            , genericForecastValue\n",
    "            , SAFE_DIVIDE(genericForecastValue , SUM(genericForecastValue) \n",
    "    OVER (PARTITION BY SNPSHT_genericTimePeriod,fcst_genericTimePeriod, cast(YR as int64), aggLevel)) KEYREC_VAL\n",
    "    from `genericDataset.forecast_data` a\n",
    "    inner join\n",
    "    `genericDataset.forecast_periods` b\n",
    "    on a.genericTimePeriod = b.eval_genericTimePeriod\n",
    "    );\n",
    "    ''',replaceDict, 'createForecast')\n",
    "    \n",
    "    with out:\n",
    "        print(datetime.datetime.now().strftime('%H:%M:%S'), 'Forecast 1 step 3/5 completed...')\n",
    "\n",
    "\n",
    "    exec_sql(\n",
    "     '''\n",
    "    create or replace table `genericDataset.value_comparison_source` genericTableOptionList as (\n",
    "    with\n",
    "    TBL2B AS (\n",
    "    SELECT t1.SNPSHT_genericTimePeriod, t1.FCST_genericTimePeriod,\n",
    "    t1.EVAL_genericTimePeriod AS TY_EVAL_genericTimePeriod, t2.EVAL_genericTimePeriod AS PREV_EVAL_genericTimePeriod, T2.YR, t3.*\n",
    "    FROM `genericDataset.forecast_periods` t1\n",
    "    INNER JOIN `genericDataset.forecast_periods` t2\n",
    "      ON T1.FCST_genericTimePeriod = T2.FCST_genericTimePeriod AND T1.genericFrequency = T2.genericFrequency\n",
    "      and t1.SNPSHT_genericTimePeriod = t2.SNPSHT_genericTimePeriod\n",
    "     cross join (select distinct aggLevel from `genericDataset.forecast_samples`) t3\n",
    "    WHERE T1.YR = 0 AND T2.YR <> 0\n",
    "    ),\n",
    "\n",
    "    Data_Start as (\n",
    "    select     aggLevel \n",
    "            , min(genericTimePeriod) as Start_Date\n",
    "            From `genericDataset.forecast_data`\n",
    "            group by 1)\n",
    "    ,\n",
    "    comp_calc as (\n",
    "    select\n",
    "    t1.SNPSHT_genericTimePeriod\n",
    "    ,t1.fcst_genericTimePeriod\n",
    "    ,t1.aggLevel, t1.yr\n",
    "    , sum(current_vals.genericForecastValue) as current_genericForecastValue\n",
    "    , sum(previous_vals.genericForecastValue) as prev_genericForecastValue \n",
    "    ,coalesce(case \n",
    "    when sum(current_vals.genericForecastValue) <= genericNumPeriods/4 and sum(previous_vals.genericForecastValue) <= genericNumPeriods/4--low volume option (reduce impact of comp)\n",
    "    then SAFE_DIVIDE(avg(current_vals.genericForecastValue),avg(previous_vals.genericForecastValue))\n",
    "    when sum(current_vals.genericForecastValue) < sum(previous_vals.genericForecastValue)--trending down (take normal values)\n",
    "    then SAFE_DIVIDE(avg(current_vals.genericForecastValue),avg(previous_vals.genericForecastValue))\n",
    "    else SAFE_DIVIDE(avg(current_vals.genericForecastValue),avg(greatest(previous_vals.genericForecastValue,1)))--trending up (minimum value for prev yrs)\n",
    "    end,1) as COMP_FCTR--new comp cap if too many 0 values\n",
    "    , SAFE_DIVIDE(1 , SUM(POWER(coalesce(current_vals.KEYREC_VAL, 0) - coalesce(previous_vals.KEYREC_VAL,0), 2))) YR_DIFF_SQRD\n",
    "    from TBL2B t1\n",
    "    left join `genericDataset.forecast_samples` current_vals\n",
    "    on t1.TY_EVAL_genericTimePeriod = current_vals.genericTimePeriod \n",
    "    and t1.fcst_genericTimePeriod = current_vals.fcst_genericTimePeriod\n",
    "    and current_vals.aggLevel = t1.aggLevel\n",
    "    and t1.SNPSHT_genericTimePeriod = current_vals.snpsht_genericTimePeriod\n",
    "    left join `genericDataset.forecast_samples` previous_vals\n",
    "    on T1.PREV_EVAL_genericTimePeriod = previous_vals.genericTimePeriod\n",
    "    and t1.fcst_genericTimePeriod = previous_vals.fcst_genericTimePeriod\n",
    "    and t1.aggLevel = previous_vals.aggLevel\n",
    "    and t1.SNPSHT_genericTimePeriod = previous_vals.snpsht_genericTimePeriod\n",
    "    inner join Data_Start start\n",
    "    on t1.aggLevel = start.aggLevel\n",
    "    group by 1,2,3,4, start.Start_Date\n",
    "    having min(t1.PREV_EVAL_genericTimePeriod) >= start.Start_Date\n",
    "    )\n",
    "    \n",
    "    select \n",
    "    *\n",
    "    from comp_calc\n",
    "    \n",
    "    );\n",
    "    ''',replaceDict, 'createForecast')\n",
    "    \n",
    "    with out:\n",
    "        print(datetime.datetime.now().strftime('%H:%M:%S'), 'Forecast 1 step 4/5 completed...')\n",
    "    \n",
    "    #split aggLevel column back out into original columns\n",
    "    columns = []\n",
    "    for i in range(len(hierarchyColumns)):\n",
    "        columns.append('''split(a.aggLevel, '|')[OFFSET({})] as {}'''.format(i, hierarchyColumns[i]))\n",
    "    deagged = ', '.join(columns)\n",
    "\n",
    "    exec_sql(\n",
    "    '''\n",
    "    create or replace table `genericDataset.genericOutputTable` as (\n",
    "\n",
    "    with\n",
    "    /*avg_comp as (\n",
    "    select\n",
    "    t1.SNPSHT_genericTimePeriod as snpsht_wk\n",
    "    ,t2.fcst_genericTimePeriod as fcst_wk, t1.aggLevel, t1.yr, avg(t1.comp_fctr) as avg_comp\n",
    "    from `genericDataset.value_comparison_source` t1--replacement vals\n",
    "    inner join `genericDataset.value_comparison_source` t2--val to be replaced\n",
    "    on t1.fcst_genericTimePeriod < t2.fcst_genericTimePeriod\n",
    "    and t1.aggLevel = t2.aggLevel\n",
    "    and t1.yr = t2.yr\n",
    "    --and t2.comp_fctr > CASE WHEN power(2,t2.yr) <= 5.1 THEN power(2,t2.yr) ELSE 5.1 END\n",
    "    --and t1.comp_fctr <= CASE WHEN power(2,t2.yr) <= 5.1 THEN power(2,t2.yr) ELSE 5.1 END\n",
    "    and t2.comp_fctr > t2.percentile_95\n",
    "    and t1.comp_fctr <= t2.percentile_95\n",
    "    group by 1,2,3,4\n",
    "    ),*/\n",
    "    avg_comp as (\n",
    "    select distinct a.*\n",
    "    ,PERCENTILE_CONT(b.comp_fctr, .1) OVER(PARTITION BY a.snpsht_genericTimePeriod, a.AGGLEVEL) as percentile_10\n",
    "    ,PERCENTILE_CONT(b.comp_fctr, .5) OVER(PARTITION BY a.snpsht_genericTimePeriod, a.AGGLEVEL) as median\n",
    "    ,PERCENTILE_CONT(b.comp_fctr, .9) OVER(PARTITION BY a.snpsht_genericTimePeriod, a.AGGLEVEL) as percentile_90\n",
    "    from\n",
    "    `genericDataset.value_comparison_source` a\n",
    "    inner join\n",
    "    `genericDataset.value_comparison_source` b\n",
    "    on a.snpsht_genericTimePeriod > b.snpsht_genericTimePeriod\n",
    "    and b.snpsht_genericTimePeriod > date_sub(a.snpsht_genericTimePeriod, interval 1 year)\n",
    "    and date_diff(a.snpsht_genericTimePeriod, a.fcst_genericTimePeriod, day) = date_diff(b.snpsht_genericTimePeriod, b.fcst_genericTimePeriod, day)\n",
    "    and a.aggLevel = b.aggLevel\n",
    "    ),\n",
    "\n",
    "    genericForecastValue_comparison as (\n",
    "    select \n",
    "    a.SNPSHT_genericTimePeriod\n",
    "    ,a.fcst_genericTimePeriod\n",
    "    ,a.aggLevel, a.yr\n",
    "    , a.current_genericForecastValue\n",
    "    , a.prev_genericForecastValue \n",
    "    , coalesce(case when b.comp_fctr > b.percentile_90 then median\n",
    "    --when b.comp_fctr < b.percentile_10 then median\n",
    "    else b.comp_fctr end\n",
    "    , a.comp_fctr) as comp_fctr\n",
    "    , a.YR_DIFF_SQRD\n",
    "    from `genericDataset.value_comparison_source` a\n",
    "    left join\n",
    "    avg_comp b\n",
    "    on\n",
    "    a.aggLevel = b.aggLevel\n",
    "    and a.yr = b.yr\n",
    "    and a.fcst_genericTimePeriod = b.fcst_genericTimePeriod\n",
    "    and a.SNPSHT_genericTimePeriod = b.snpsht_genericTimePeriod\n",
    "    ),\n",
    "\n",
    "    weights as (\n",
    "    SELECT\n",
    "    A.SNPSHT_genericTimePeriod\n",
    "    ,A.fcst_genericTimePeriod\n",
    "    ,YR\n",
    "    ,a.aggLevel\n",
    "    ,A.yr_diff_sqrd\n",
    "    ,b.ttl_yr_diff_sqrd\n",
    "    , SAFE_DIVIDE(A.YR_DIFF_SQRD , B.TTL_YR_DIFF_SQRD) WEIGHT\n",
    "    , A.comp_fctr\n",
    "    from   genericForecastValue_comparison A\n",
    "    left join\n",
    "    (select SNPSHT_genericTimePeriod, fcst_genericTimePeriod, aggLevel\n",
    "    ,sum(YR_DIFF_SQRD) ttl_YR_DIFF_SQRD\n",
    "    from `genericDataset.value_comparison_source`\n",
    "    group by 1,2,3) B\n",
    "    on A.fcst_genericTimePeriod = B.fcst_genericTimePeriod\n",
    "    and a.aggLevel = b.aggLevel\n",
    "    and a.SNPSHT_genericTimePeriod = b.SNPSHT_genericTimePeriod\n",
    "    ),\n",
    "\n",
    "    years_history as (\n",
    "    select SNPSHT_genericTimePeriod, fcst_genericTimePeriod, aggLevel, count(distinct yr) as years_available\n",
    "    from weights\n",
    "    group by 1,2,3\n",
    "    ),\n",
    "\n",
    "     missing_samples as(\n",
    "        select * from `genericDataset.forecast_samples`\n",
    "    where concat(cast(snpsht_genericTimePeriod as string), aggLevel) not in (select distinct concat(cast(snpsht_genericTimePeriod as string), aggLevel) from years_history)\n",
    "    --find any aggs/week combos that are present in historic data, but not in forecast data (because dont have minimum 1 year + 13 period history)\n",
    "    ),\n",
    "\n",
    "\n",
    "\n",
    "    forecast as (\n",
    "    select\n",
    "    b.SNPSHT_genericTimePeriod\n",
    "    ,b.fcst_genericTimePeriod\n",
    "    ,b.aggLevel\n",
    "    ,coalesce( forecastTransform1 sum(a.genericForecastValue * b.weight * b.comp_fctr) forecastTransform2 ,0) as forecast1_genericForecastValue--multi year history\n",
    "    --,coalesce(sum(a.genericForecastValue * b.weight * b.comp_fctr),0) as exact_forecast1_genericForecastValue\n",
    "    from `genericDataset.forecast_data` a\n",
    "    inner join weights b\n",
    "\n",
    "\n",
    "\n",
    "    --on date_diff(date_trunc((date_sub(b.fcst_genericTimePeriod, interval DATE_DIFF(b.fcst_genericTimePeriod, a.genericTimePeriod,YEAR) YEAR))\n",
    "    --, week(a.weekday)), a.genericTimePeriod,genericFrequency) = 0\n",
    "\n",
    "    on date_diff(date_sub(b.fcst_genericTimePeriod, interval DATE_DIFF(b.fcst_genericTimePeriod, a.genericTimePeriod,YEAR) YEAR), a.genericTimePeriod,week) = 0\n",
    "    and extract(DAYOFWEEK from b.fcst_genericTimePeriod) = a.dayofweek\n",
    "\n",
    "\n",
    "\n",
    "    --on MOD(DATE_DIFF(b.fcst_genericTimePeriod,a.genericTimePeriod,WEEK),52) = 0--multi year join\n",
    "    and DATE_DIFF(b.fcst_genericTimePeriod, a.genericTimePeriod,YEAR) = b.yr\n",
    "        AND a.aggLevel = b.aggLevel\n",
    "    left join years_history history\n",
    "    on b.snpsht_genericTimePeriod = history.snpsht_genericTimePeriod\n",
    "        and b.fcst_genericTimePeriod = history.fcst_genericTimePeriod\n",
    "        and history.aggLevel = b.aggLevel\n",
    "    where history.years_available > 1    \n",
    "    group by 1,2,3\n",
    "    union all\n",
    "    select\n",
    "    b.SNPSHT_genericTimePeriod\n",
    "    ,b.fcst_genericTimePeriod\n",
    "    ,b.aggLevel\n",
    "    ,coalesce( forecastTransform1 b.avg_genericForecastValue forecastTransform2 ,0) as DS_genericForecastValue\n",
    "    --,coalesce(b.avg_genericForecastValue,0) as exact_DS_genericForecastValue\n",
    "    from\n",
    "    (SELECT t3.snpsht_genericTimePeriod, t3.fcst_genericTimePeriod\n",
    "    ,t3.aggLevel\n",
    "    ,avg(t3.genericForecastValue) as avg_genericForecastValue\n",
    "    FROM  `genericDataset.forecast_periods` t1\n",
    "    inner join `genericDataset.forecast_samples` t3\n",
    "    on t1.snpsht_genericTimePeriod = t3.snpsht_genericTimePeriod\n",
    "    and t1.fcst_genericTimePeriod = t3.fcst_genericTimePeriod\n",
    "    and t1.eval_genericTimePeriod = t3.genericTimePeriod\n",
    "    WHERE T1.YR = 0\n",
    "    group by 1,2,3) b\n",
    "    left join years_history history\n",
    "    on b.snpsht_genericTimePeriod = history.snpsht_genericTimePeriod\n",
    "        and b.fcst_genericTimePeriod = history.fcst_genericTimePeriod\n",
    "        and history.aggLevel = b.aggLevel\n",
    "    where history.years_available <= 1\n",
    "    union all\n",
    "    select snpsht_genericTimePeriod, fcst_genericTimePeriod, aggLevel\n",
    "    , coalesce( forecastTransform1 avg(genericForecastValue) forecastTransform2 ,0) as forecast1_genericForecastValue\n",
    "    --, coalesce(avg(genericForecastValue),0) as exact_forecast1_genericForecastValue\n",
    "    from missing_samples\n",
    "    group by 1,2,3\n",
    "    )\n",
    "\n",
    "    select\n",
    "    a.*, cast(0.0 as float64) as forecast2_genericForecastValue--, cast(null as float64) as exact_forecast2_genericForecastValue\n",
    "    , cast(0.0 as float64) as forecast3_genericForecastValue--, cast(null as float64) as exact_forecast3_genericForecastValue\n",
    "    , cast(null as float64) as forecast4_genericForecastValue\n",
    "    , cast(null as float64) as one_forecast_genericForecastValue\n",
    "    , cast(b.genericForecastValue as float64) as actual_genericForecastValue\n",
    "    ,{}\n",
    "    from forecast a\n",
    "    left join `genericDataset.forecast_data` b\n",
    "    on a.fcst_genericTimePeriod = b.genericTimePeriod\n",
    "    and a.aggLevel = b.aggLevel\n",
    "\n",
    "    );\n",
    "    '''.format(deagged),replaceDict, 'createForecast'\n",
    "    ,altSQL='''\n",
    "    create or replace table `genericDataset.KERNEL_FCST` genericTableOptionList as (\n",
    "    with\n",
    "    avg_comp as (\n",
    "    select\n",
    "    t1.SNPSHT_genericTimePeriod as snpsht_wk\n",
    "    ,t2.fcst_genericTimePeriod as fcst_wk, t1.aggLevel, t1.yr, avg(t1.comp_fctr) as avg_comp\n",
    "    from `genericDataset.value_comparison_source` t1--replacement vals\n",
    "    inner join `genericDataset.value_comparison_source` t2--val to be replaced\n",
    "    on t1.fcst_genericTimePeriod < t2.fcst_genericTimePeriod\n",
    "    and t1.aggLevel = t2.aggLevel\n",
    "    and t1.yr = t2.yr\n",
    "    and t2.comp_fctr > CASE WHEN power(2,t2.yr) <= 5.1 THEN power(2,t2.yr) ELSE 5.1 END\n",
    "    and t1.comp_fctr <= CASE WHEN power(2,t2.yr) <= 5.1 THEN power(2,t2.yr) ELSE 5.1 END\n",
    "    group by 1,2,3,4\n",
    "    ),\n",
    "\n",
    "    genericForecastValue_comparison as (\n",
    "    select \n",
    "    a.SNPSHT_genericTimePeriod\n",
    "    ,a.fcst_genericTimePeriod\n",
    "    ,a.aggLevel, a.yr\n",
    "    , a.current_genericForecastValue\n",
    "    , a.prev_genericForecastValue \n",
    "    , a.comp_fctr\n",
    "    , a.YR_DIFF_SQRD\n",
    "    from `genericDataset.value_comparison_source` a\n",
    "    left join\n",
    "    avg_comp b\n",
    "    on\n",
    "    a.aggLevel = b.aggLevel\n",
    "    and a.yr = b.yr\n",
    "    and a.fcst_genericTimePeriod = b.fcst_wk\n",
    "    and a.SNPSHT_genericTimePeriod = b.snpsht_wk\n",
    "    ),\n",
    "\n",
    "    weights as (\n",
    "    SELECT\n",
    "    A.SNPSHT_genericTimePeriod\n",
    "    ,A.fcst_genericTimePeriod\n",
    "    ,YR\n",
    "    ,a.aggLevel\n",
    "    ,A.yr_diff_sqrd\n",
    "    ,b.ttl_yr_diff_sqrd\n",
    "    , SAFE_DIVIDE(A.YR_DIFF_SQRD , B.TTL_YR_DIFF_SQRD) WEIGHT\n",
    "    , A.comp_fctr\n",
    "    from   genericForecastValue_comparison A\n",
    "    left join\n",
    "    (select SNPSHT_genericTimePeriod, fcst_genericTimePeriod, aggLevel\n",
    "    ,sum(YR_DIFF_SQRD) ttl_YR_DIFF_SQRD\n",
    "    from `genericDataset.value_comparison_source`\n",
    "    group by 1,2,3) B\n",
    "    on A.fcst_genericTimePeriod = B.fcst_genericTimePeriod\n",
    "    and a.aggLevel = b.aggLevel\n",
    "    and a.SNPSHT_genericTimePeriod = b.SNPSHT_genericTimePeriod\n",
    "    ),\n",
    "\n",
    "    years_history as (\n",
    "    select SNPSHT_genericTimePeriod, fcst_genericTimePeriod, aggLevel, count(distinct yr) as years_available\n",
    "    from weights\n",
    "    group by 1,2,3\n",
    "    ),\n",
    "\n",
    "     missing_samples as(\n",
    "        select * from `genericDataset.forecast_samples`\n",
    "    where concat(cast(snpsht_genericTimePeriod as string), aggLevel) not in (select distinct concat(cast(snpsht_genericTimePeriod as string), aggLevel) from years_history)\n",
    "    --find any aggs/week combos that are present in historic data, but not in forecast data (because dont have minimum 1 year + 13 period history)\n",
    "    ),\n",
    "\n",
    "\n",
    "\n",
    "    forecast as (\n",
    "    select\n",
    "    b.SNPSHT_genericTimePeriod\n",
    "    ,b.fcst_genericTimePeriod\n",
    "    ,b.aggLevel\n",
    "    ,coalesce( forecastTransform1 sum(a.genericForecastValue * b.weight * b.comp_fctr) forecastTransform2 ,0) as forecast1_genericForecastValue--multi year history\n",
    "    --,coalesce(sum(a.genericForecastValue * b.weight * b.comp_fctr),0) as exact_forecast1_genericForecastValue\n",
    "    from `genericDataset.forecast_data` a\n",
    "    inner join weights b\n",
    "\n",
    "\n",
    "\n",
    "    --on date_diff(date_trunc((date_sub(b.fcst_genericTimePeriod, interval DATE_DIFF(b.fcst_genericTimePeriod, a.genericTimePeriod,YEAR) YEAR))\n",
    "    --, week(a.weekday)), a.genericTimePeriod,genericFrequency) = 0\n",
    "\n",
    "    on date_diff(date_sub(b.fcst_genericTimePeriod, interval DATE_DIFF(b.fcst_genericTimePeriod, a.genericTimePeriod,YEAR) YEAR), a.genericTimePeriod,week) = 0\n",
    "    and extract(DAYOFWEEK from b.fcst_genericTimePeriod) = a.dayofweek\n",
    "\n",
    "\n",
    "\n",
    "    --on MOD(DATE_DIFF(b.fcst_genericTimePeriod,a.genericTimePeriod,WEEK),52) = 0--multi year join\n",
    "    and DATE_DIFF(b.fcst_genericTimePeriod, a.genericTimePeriod,YEAR) = b.yr\n",
    "        AND a.aggLevel = b.aggLevel\n",
    "    left join years_history history\n",
    "    on b.snpsht_genericTimePeriod = history.snpsht_genericTimePeriod\n",
    "        and b.fcst_genericTimePeriod = history.fcst_genericTimePeriod\n",
    "        and history.aggLevel = b.aggLevel\n",
    "    where history.years_available > 1    \n",
    "    group by 1,2,3\n",
    "    union all\n",
    "    select\n",
    "    b.SNPSHT_genericTimePeriod\n",
    "    ,b.fcst_genericTimePeriod\n",
    "    ,b.aggLevel\n",
    "    ,coalesce( forecastTransform1 b.avg_genericForecastValue forecastTransform2 ,0) as DS_genericForecastValue\n",
    "    --,coalesce(b.avg_genericForecastValue,0) as exact_DS_genericForecastValue\n",
    "    from\n",
    "    (SELECT t3.snpsht_genericTimePeriod, t3.fcst_genericTimePeriod\n",
    "    ,t3.aggLevel\n",
    "    ,avg(t3.genericForecastValue) as avg_genericForecastValue\n",
    "    FROM  `genericDataset.forecast_periods` t1\n",
    "    inner join `genericDataset.forecast_samples` t3\n",
    "    on t1.snpsht_genericTimePeriod = t3.snpsht_genericTimePeriod\n",
    "    and t1.fcst_genericTimePeriod = t3.fcst_genericTimePeriod\n",
    "    and t1.eval_genericTimePeriod = t3.genericTimePeriod\n",
    "    WHERE T1.YR = 0\n",
    "    group by 1,2,3) b\n",
    "    left join years_history history\n",
    "    on b.snpsht_genericTimePeriod = history.snpsht_genericTimePeriod\n",
    "        and b.fcst_genericTimePeriod = history.fcst_genericTimePeriod\n",
    "        and history.aggLevel = b.aggLevel\n",
    "    where history.years_available <= 1\n",
    "    union all\n",
    "    select snpsht_genericTimePeriod, fcst_genericTimePeriod, aggLevel\n",
    "    , coalesce( forecastTransform1 avg(genericForecastValue) forecastTransform2 ,0) as forecast1_genericForecastValue\n",
    "    --, coalesce(avg(genericForecastValue),0) as exact_forecast1_genericForecastValue\n",
    "    from missing_samples\n",
    "    group by 1,2,3\n",
    "    )\n",
    "\n",
    "    select\n",
    "    a.*, cast(null as float64) as forecast2_genericForecastValue--, cast(null as float64) as exact_forecast2_genericForecastValue\n",
    "    , cast(null as float64) as forecast3_genericForecastValue--, cast(null as float64) as exact_forecast3_genericForecastValue\n",
    "    , cast(null as float64) as forecast4_genericForecastValue\n",
    "    , cast(null as float64) as one_forecast_genericForecastValue\n",
    "    , cast(b.genericForecastValue as float64) as actual_genericForecastValue\n",
    "    ,{}\n",
    "    from forecast a\n",
    "    left join `genericDataset.forecast_data` b\n",
    "    on a.fcst_genericTimePeriod = b.genericTimePeriod\n",
    "    and a.aggLevel = b.aggLevel);\n",
    "    \n",
    "    \n",
    "    \n",
    "    create or replace table `genericDataset.genericOutputTable_copy` as (\n",
    "    select * from `genericDataset.genericOutputTable`\n",
    "    );\n",
    "    \n",
    "    create or replace table `genericDataset.genericOutputTable` as (\n",
    "    select * from `genericDataset.genericOutputTable_copy`\n",
    "    union distinct\n",
    "    select * from `genericDataset.KERNEL_FCST` where snpsht_genericTimePeriod = date_trunc(current_date(), genericFrequency)\n",
    "    \n",
    "    );\n",
    "\n",
    "    '''.format(deagged)\n",
    "    )\n",
    "\n",
    "    with out:\n",
    "        print(datetime.datetime.now().strftime('%H:%M:%S'), 'Forecast 1 step 5/5 completed, forecast created successfully...')\n",
    "    display(Javascript(\"execCellsByTag('Forecast2')\"))\n",
    "except:\n",
    "    with out:\n",
    "        print(datetime.datetime.now().strftime('%H:%M:%S'), 'Error: Invalid input detected while generating forecast 1. Please verify inputs and try again.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "Forecast2"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    exec_sql('''\n",
    "    CREATE OR REPLACE TABLE `genericDataset.BQML_SEASONAL_CALENDAR` genericTableOptionList AS (\n",
    "    WITH TBL1 AS (\n",
    "    SELECT *\n",
    "      , MAX(DAILY_HOLIDAY) OVER (PARTITION BY FSCL_WK_END_DT) AS WEEKLY_HOLIDAY\n",
    "      , CONCAT('BEFORE ', LEAD(DAILY_HOLIDAY) OVER (ORDER BY CAL_DT)) AS LEAD_DAILY_HOLIDAY\n",
    "      , CONCAT('AFTER ', LAG(DAILY_HOLIDAY) OVER (ORDER BY CAL_DT)) AS LAG_DAILY_HOLIDAY\n",
    "    FROM (\n",
    "      SELECT *\n",
    "        , CASE WHEN (MONTH = 1 AND DAY = 1 AND DAYOFWEEK BETWEEN 2 AND 6) OR (MONTH = 1 AND DAY = 2 AND DAYOFWEEK = 2) OR (MONTH = 12 AND DAY = 31 AND DAYOFWEEK = 6) THEN 'NEW YEARS'\n",
    "            --WHEN MONTH = 5 AND DAY BETWEEN 25 AND 31 AND DAYOFWEEK = 2 THEN 0\n",
    "            --WHEN (MONTH = 7 AND DAY = 4 AND DAYOFWEEK BETWEEN 2 AND 6) OR (MONTH = 7 AND DAY = 5 AND DAYOFWEEK = 2) OR (MONTH = 7 AND DAY = 3 AND DAYOFWEEK = 6) THEN 0\n",
    "            --WHEN MONTH = 9 AND DAY BETWEEN 1 AND 7 AND DAYOFWEEK = 2 THEN 0\n",
    "            WHEN MONTH = 11 AND DAY BETWEEN 22 AND 28 AND DAYOFWEEK = 5 THEN 'THANKSGIVING'\n",
    "            WHEN (MONTH = 12 AND DAY = 25 AND DAYOFWEEK BETWEEN 2 AND 6) OR (MONTH = 12 AND DAY = 26 AND DAYOFWEEK = 2) OR (MONTH = 12 AND DAY = 24 AND DAYOFWEEK = 6) THEN 'CHRISTMAS'\n",
    "            ELSE NULL END AS DAILY_HOLIDAY\n",
    "      FROM (\n",
    "        SELECT *\n",
    "          , EXTRACT(MONTH FROM CAL_DT) AS MONTH, EXTRACT(DAY FROM CAL_DT) AS DAY, EXTRACT(DAYOFWEEK FROM CAL_DT) AS DAYOFWEEK\n",
    "        FROM `pr-edw-views-thd.SHARED.CAL_PRD_HIER_FD`\n",
    "      )\n",
    "    )\n",
    "    )\n",
    "    , TBL2 AS (\n",
    "    SELECT *\n",
    "      , CONCAT('BEFORE ', LEAD(WEEKLY_HOLIDAY) OVER (ORDER BY FSCL_WK_END_DT)) AS LEAD_WEEKLY_HOLIDAY\n",
    "      , CONCAT('AFTER ', LAG(WEEKLY_HOLIDAY) OVER (ORDER BY FSCL_WK_END_DT)) AS LAG_WEEKLY_HOLIDAY\n",
    "    FROM (SELECT DISTINCT FSCL_WK_END_DT, WEEKLY_HOLIDAY FROM TBL1)\n",
    "    )\n",
    "    , TBL3 AS (\n",
    "    SELECT A.CAL_DT, A.FSCL_WK_END_DT, A.FSCL_PRD_END_DT\n",
    "      , COALESCE(A.DAILY_HOLIDAY, A.LEAD_DAILY_HOLIDAY, A.LAG_DAILY_HOLIDAY, CAST(A.DAYOFWEEK AS STRING)) AS DAILY_SEASON\n",
    "      , CASE WHEN A.DAILY_HOLIDAY IS NULL AND A.LEAD_DAILY_HOLIDAY IS NULL AND A.LAG_DAILY_HOLIDAY IS NULL THEN FALSE ELSE TRUE END AS DAILY_HOLIDAY_FLG\n",
    "      , COALESCE(A.WEEKLY_HOLIDAY, B.LEAD_WEEKLY_HOLIDAY, B.LAG_WEEKLY_HOLIDAY, CAST(CASE WHEN A.FSCL_WK_NBR = 53 THEN 52 ELSE FSCL_WK_NBR END AS STRING)) AS WEEKLY_SEASON\n",
    "      , CASE WHEN A.WEEKLY_HOLIDAY IS NULL AND B.LEAD_WEEKLY_HOLIDAY IS NULL AND B.LAG_WEEKLY_HOLIDAY IS NULL THEN FALSE ELSE TRUE END AS WEEKLY_HOLIDAY_FLG\n",
    "      , FSCL_PRD_NBR AS MONTHLY_SEASON\n",
    "    FROM TBL1 A\n",
    "    INNER JOIN TBL2 B\n",
    "      ON A.FSCL_WK_END_DT = B.FSCL_WK_END_DT\n",
    "    )\n",
    "    , TBL4 AS (\n",
    "    SELECT *\n",
    "        , SEASONALITY[OFFSET(0)].HOLIDAY_FLG AS HOLIDAY_FLG\n",
    "    FROM (\n",
    "    SELECT CAL_DT AS DT\n",
    "        , genericSeasonality AS SEASONALITY\n",
    "    FROM TBL3\n",
    "    WHERE CAL_DT = genericCalendarColumn\n",
    "    )\n",
    "    )\n",
    "    SELECT *\n",
    "        , ARRAY_AGG(DT) OVER (ORDER BY DT ROWS BETWEEN 1 FOLLOWING AND snapshotPeriods FOLLOWING) AS FCST_DTS\n",
    "        , ROW_NUMBER() OVER (ORDER BY DT) AS DT_RNK\n",
    "        , LEAD(DT) OVER (ORDER BY DT) AS NEXT_DT\n",
    "    FROM TBL4\n",
    "    );\n",
    "    ''',replaceDict, 'createForecast')\n",
    "    with out:\n",
    "         print(datetime.datetime.now().strftime('%H:%M:%S'), 'Forecast 2 step 1/9 completed...')\n",
    "    \n",
    "    exec_sql('''\n",
    "    CREATE OR REPLACE TABLE `genericDataset.BQML_SEASONAL_SMOOTHING_CALENDAR` genericTableOptionList AS (\n",
    "    WITH TYPES AS (\n",
    "    genericSeasonalUnion\n",
    "    )\n",
    "    , NON_HOLIDAY_CAL AS (\n",
    "    SELECT *\n",
    "        , ROW_NUMBER() OVER (ORDER BY DT) AS NON_HOLIDAY_DT_RNK\n",
    "    FROM `genericDataset.BQML_SEASONAL_CALENDAR`\n",
    "    WHERE NOT HOLIDAY_FLG\n",
    "    )\n",
    "    SELECT B.TYPE, A.DT, C.DT AS SMOOTH_DT\n",
    "    FROM NON_HOLIDAY_CAL A\n",
    "    CROSS JOIN TYPES B\n",
    "    CROSS JOIN NON_HOLIDAY_CAL C\n",
    "    WHERE C.NON_HOLIDAY_DT_RNK BETWEEN A.NON_HOLIDAY_DT_RNK - (B.LAGS - 1) / 2 AND A.NON_HOLIDAY_DT_RNK + (B.LAGS - 1) / 2\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT B.TYPE, A.DT, A.DT AS SMOOTH_DT\n",
    "    FROM `genericDataset.BQML_SEASONAL_CALENDAR` A\n",
    "    CROSS JOIN TYPES B\n",
    "    WHERE HOLIDAY_FLG\n",
    "    );\n",
    "    ''',replaceDict, 'createForecast')\n",
    "    with out:\n",
    "        print(datetime.datetime.now().strftime('%H:%M:%S'), 'Forecast 2 step 2/9 completed...')\n",
    "    \n",
    "    exec_sql('''\n",
    "    /*CREATE TEMP TABLE TBL1 AS (\n",
    "    SELECT CONCAT(genericHierarchy) AS KEY\n",
    "        , genericTimePeriod AS DT\n",
    "        , SUM(genericForecastValue) AS QTY\n",
    "    FROM `genericInputTable`\n",
    "    GROUP BY 1,2\n",
    "    );*/\n",
    "\n",
    "    CREATE OR REPLACE TABLE `genericDataset.BQML_DATA` genericTableOptionList AS (\n",
    "    WITH TBL1 AS (\n",
    "        SELECT CONCAT(genericHierarchy) AS KEY\n",
    "        , genericTimePeriod AS DT\n",
    "        , SUM(genericForecastValue) AS QTY\n",
    "        FROM `genericInputTable`\n",
    "        GROUP BY 1,2\n",
    "    ),\n",
    "    KEYS AS ( --CONTROL FOR KEYS APPEARING MIDWAY THROUGH DATA BY TAKING KEY SPECIFIC MIN\n",
    "    SELECT A.KEY, MIN(B.DT_RNK) AS MIN_DT_RNK\n",
    "    FROM TBL1 A\n",
    "    INNER JOIN `genericDataset.BQML_SEASONAL_CALENDAR` B\n",
    "        ON A.DT = B.DT\n",
    "    WHERE A.QTY > 0\n",
    "    GROUP BY 1\n",
    "    )\n",
    "    , MAX_DT AS ( --WANT ALL KEYS TO END AT SAME POINT, SO DON'T TAKE KEY SPECIFIC MAX\n",
    "    SELECT MAX(B.DT_RNK) AS MAX_DT_RNK\n",
    "    FROM TBL1 A\n",
    "    INNER JOIN `genericDataset.BQML_SEASONAL_CALENDAR` B\n",
    "        ON A.DT = B.DT\n",
    "    )\n",
    "    , TBL2 AS (\n",
    "    SELECT A.KEY\n",
    "        , C.DT\n",
    "        , C.SEASONALITY\n",
    "        , C.FCST_DTS\n",
    "        , C.NEXT_DT\n",
    "        , C.DT_RNK BETWEEN A.MIN_DT_RNK AND B.MAX_DT_RNK AS FCST_CRT_DT_FLG --PUSH DATA OUT TO COMPUTE SEASONALITY VALUES FOR ALL NEEDED WEEKS, THIS IS HOW TO RECOVER WEEKS WHERE WE CREATE A FORECAST\n",
    "        , CASE WHEN C.DT_RNK BETWEEN A.MIN_DT_RNK AND B.MAX_DT_RNK THEN COALESCE(D.QTY, 0.0) ELSE NULL END AS QTY\n",
    "    FROM KEYS A\n",
    "    CROSS JOIN MAX_DT B\n",
    "    CROSS JOIN `genericDataset.BQML_SEASONAL_CALENDAR` C\n",
    "    LEFT JOIN TBL1 D\n",
    "        ON A.KEY = D.KEY AND C.DT = D.DT\n",
    "    WHERE C.DT_RNK BETWEEN A.MIN_DT_RNK - (genericSeasonalLags - 1) / 2 AND B.MAX_DT_RNK + (genericSeasonalLags - 1) / 2 + snapshotPeriods\n",
    "    )\n",
    "    , TBL3 AS (\n",
    "    SELECT *\n",
    "        , LEAST(GREATEST(QTY, PERCENTILE_1), PERCENTILE_99) AS ADJ_QTY\n",
    "    FROM (\n",
    "        SELECT A.*\n",
    "            , PERCENTILE_CONT(QTY, .99) OVER (PARTITION BY KEY) AS PERCENTILE_99\n",
    "            , PERCENTILE_CONT(QTY, .01) OVER (PARTITION BY KEY) AS PERCENTILE_1\n",
    "        FROM TBL2 A\n",
    "    )\n",
    "    )\n",
    "    SELECT *\n",
    "        , AVG(ADJ_QTY) OVER (PARTITION BY KEY ORDER BY DT ROWS BETWEEN genericNumPeriods PRECEDING AND 1 PRECEDING) AS PERIOD_AVG_QTY\n",
    "        , COUNT(ADJ_QTY) OVER (PARTITION BY KEY ORDER BY DT ROWS BETWEEN genericNumPeriods PRECEDING AND 1 PRECEDING) AS PERIOD_COUNT_QTY\n",
    "    FROM TBL3\n",
    "    );\n",
    "    ''',replaceDict, 'createForecast')\n",
    "    with out:\n",
    "        print(datetime.datetime.now().strftime('%H:%M:%S'), 'Forecast 2 step 3/9 completed...')\n",
    "\n",
    "    exec_sql('''\n",
    "    CREATE OR REPLACE TABLE `genericDataset.BQML_SEASONALITY` genericTableOptionList AS (\n",
    "    SELECT * EXCEPT(SEASONAL_QTY)\n",
    "        , SAFE_DIVIDE(SUM(SEASONAL_QTY) OVER (PARTITION BY KEY, TYPE, SEASON) - COALESCE(SEASONAL_QTY, 0), \n",
    "                      COUNT(SEASONAL_QTY) OVER (PARTITION BY KEY, TYPE, SEASON) - CASE WHEN SEASONAL_QTY IS NOT NULL THEN 1 ELSE 0 END) AS SEASONAL_QTY\n",
    "            --SEASONAL ESTIMATE IS AVERAGE OF VALUES EXCLUDING CURRENT ROW - THAT WAY WE'RE KEEPING THE FORECAST FOR A DATE INDEPENDENT OF THE VALUE FOR THAT DATE\n",
    "    FROM (\n",
    "        SELECT A.KEY, A.DT\n",
    "            , SEASONALITY.TYPE\n",
    "            , SEASONALITY.SEASON\n",
    "            , CASE WHEN PERIOD_COUNT_QTY = genericNumPeriods THEN A.ADJ_QTY - A.PERIOD_AVG_QTY ELSE NULL END AS SEASONAL_QTY\n",
    "                --IF WE DON'T HAVE A FULL PERIOD OF DATA THEN OUR SEASONAL ESTIMATE WILL BE BIASED\n",
    "        FROM `genericDataset.BQML_DATA` A\n",
    "        CROSS JOIN UNNEST(A.SEASONALITY) AS SEASONALITY\n",
    "    )\n",
    "    );\n",
    "    ''',replaceDict, 'createForecast')\n",
    "    with out:\n",
    "        print(datetime.datetime.now().strftime('%H:%M:%S'), 'Forecast 2 step 4/9 completed...')\n",
    "    \n",
    "    exec_sql('''\n",
    "    CREATE TEMP FUNCTION DOT(V1 ANY TYPE, V2 ANY TYPE) AS ((\n",
    "    --SELECT SUM(X1 * V2[OFFSET(I)])\n",
    "    SELECT SUM(X1 * CASE WHEN IS_NAN(V2[OFFSET(I)]) THEN NULL ELSE V2[OFFSET(I)] END)\n",
    "    FROM UNNEST(V1) X1 WITH OFFSET I\n",
    "    ));\n",
    "\n",
    "    CREATE TEMP FUNCTION SMOOTH(A ANY TYPE, DECAY FLOAT64) AS ((\n",
    "    SELECT DOT(ARRAY_AGG(WT / SUM_WTS ORDER BY I), A)\n",
    "    FROM (\n",
    "      SELECT *\n",
    "        , SUM(WT) OVER () AS SUM_WTS\n",
    "      FROM (\n",
    "        SELECT I\n",
    "          , POW(DECAY, ABS((ARRAY_LENGTH(A) - 1) / 2 - I)) AS WT\n",
    "        FROM UNNEST(GENERATE_ARRAY(0, ARRAY_LENGTH(A) - 1)) I\n",
    "      )\n",
    "    )\n",
    "    ));\n",
    "    \n",
    "    CREATE OR REPLACE TABLE `genericDataset.BQML_SEASONALITY_SMOOTHED` genericTableOptionList AS (\n",
    "    SELECT KEY, DT\n",
    "        , SUM(SMOOTH(SEASONAL_QTYS, .5)) AS SMOOTHED_SEASONAL_QTY\n",
    "        , SUM(SMOOTH(SEASONAL_QTYS, 0)) AS SEASONAL_QTY --USING 0 HERE PROVIDES NO SMOOTHING AT ALL, USED FOR AGGRESSIVE FORECAST, ALSO A BACKUP IN CASE WE HAVE LITTLE HISTORY\n",
    "    FROM (\n",
    "        SELECT A.KEY, A.DT, A.TYPE\n",
    "            , ARRAY_AGG(COALESCE(C.SEASONAL_QTY, CAST('NAN' AS FLOAT64)) ORDER BY B.DT) AS SEASONAL_QTYS\n",
    "        FROM `genericDataset.BQML_SEASONALITY` A\n",
    "        INNER JOIN `genericDataset.BQML_SEASONAL_SMOOTHING_CALENDAR` B\n",
    "            ON A.TYPE = B.TYPE AND A.DT = B.DT\n",
    "        LEFT JOIN `genericDataset.BQML_SEASONALITY` C\n",
    "            ON A.KEY = C.KEY AND A.TYPE = C.TYPE AND B.SMOOTH_DT = C.DT\n",
    "        GROUP BY 1,2,3\n",
    "    )\n",
    "    GROUP BY 1,2\n",
    "    );\n",
    "    ''',replaceDict, 'createForecast')\n",
    "    with out:\n",
    "        print(datetime.datetime.now().strftime('%H:%M:%S'), 'Forecast 2 step 5/9 completed...')\n",
    "    \n",
    "    exec_sql('''\n",
    "\n",
    "    CREATE OR REPLACE TABLE `genericDataset.BQML_EXP_SMOOTH_DATA` genericTableOptionList AS (\n",
    "    SELECT A.KEY\n",
    "        , A.DT\n",
    "        , A.NEXT_DT\n",
    "        , A.FCST_DTS\n",
    "        , A.FCST_CRT_DT_FLG\n",
    "        , A.QTY\n",
    "        , A.ADJ_QTY\n",
    "        , COALESCE(B.SMOOTHED_SEASONAL_QTY, B.SEASONAL_QTY, 0) AS SMOOTHED_SEASONAL_QTY\n",
    "        , A.ADJ_QTY - COALESCE(B.SMOOTHED_SEASONAL_QTY, B.SEASONAL_QTY, 0) AS DESEASONALIZED_ADJ_QTY\n",
    "        , COALESCE(B.SEASONAL_QTY, 0) AS SEASONAL_QTY\n",
    "        , A.ADJ_QTY - COALESCE(B.SEASONAL_QTY, 0) AS ST_DESEASONALIZED_ADJ_QTY\n",
    "    FROM `genericDataset.BQML_DATA` A\n",
    "    INNER JOIN `genericDataset.BQML_SEASONALITY_SMOOTHED` B\n",
    "        ON A.KEY = B.KEY AND A.DT = B.DT\n",
    "    );\n",
    "    ''',replaceDict, 'createForecast')\n",
    "    with out:\n",
    "        print(datetime.datetime.now().strftime('%H:%M:%S'), 'Forecast 2 step 6/9 completed...')\n",
    "\n",
    "    exec_sql('''\n",
    "    CREATE TEMP FUNCTION EXP_SMOOTH(data ARRAY<STRUCT<dt DATE, deseasonalized_adj_qty FLOAT64, st_deseasonalized_adj_qty FLOAT64>>)\n",
    "    RETURNS STRUCT<data ARRAY<STRUCT<dt DATE, deseasonalized_adj_qty FLOAT64, st_deseasonalized_adj_qty FLOAT64, fcst_deseasonalized_qty FLOAT64, st_fcst_deseasonalized_qty FLOAT64>>, \n",
    "                   alpha FLOAT64, alpha_h1 FLOAT64, alpha_h2 FLOAT64, alpha_q1 FLOAT64, alpha_q2 FLOAT64, alpha_q3 FLOAT64, alpha_q4 FLOAT64>\n",
    "    LANGUAGE js\n",
    "    AS \"\"\"\n",
    "    function golden_section_search(f, lb, ub, tol) { //https://en.wikipedia.org/wiki/Golden-section_search\n",
    "        var gr = 1.618033988\n",
    "        var x1 = {x: lb, y: f(lb)}\n",
    "        var x2 = {x: (ub + gr * lb) / (gr + 1)}\n",
    "        x2.y = f(x2.x)\n",
    "        var x3 = {x: ub, y: f(lb)}\n",
    "        function search(f, x1, x2, x3, tol) {\n",
    "            if (x3.x - x1.x < tol) {\n",
    "                return (x1.x + x3.x) / 2\n",
    "            }\n",
    "            var x4 = {x: x1.x + (x3.x - x2.x)}\n",
    "            x4.y = f(x4.x)\n",
    "            if (x4.x > x2.x) {\n",
    "                if (x4.y < x2.y) {\n",
    "                    return search(f, x2, x4, x3, tol)\n",
    "                } else {\n",
    "                    return search(f, x1, x2, x4, tol)\n",
    "                }\n",
    "            }\n",
    "            else {\n",
    "                if (x4.y < x2.y) {\n",
    "                    return search(f, x1, x4, x2, tol)\n",
    "                } else {\n",
    "                    return search(f, x4, x2, x3, tol)\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        return search(f, x1, x2, x3, tol)\n",
    "    }\n",
    "    \n",
    "    function fit(alpha, input_col, sse_low, sse_high, output_col, output_low, output_high) {\n",
    "        data[0].temp = data[0][input_col]\n",
    "        var sse = 0\n",
    "        data.forEach((d, i) => {\n",
    "            if (i >= 1) {\n",
    "                d.temp = alpha * data[i][input_col] + (1 - alpha) * data[i-1].temp\n",
    "                if (i >= sse_low && i <= sse_high) {\n",
    "                    sse += Math.pow(d[input_col] - data[i-1].temp, 2)\n",
    "                }\n",
    "                if (output_col != undefined && i >= output_low && i <= output_high) {\n",
    "                    d[output_col] = d.temp\n",
    "                }\n",
    "            }\n",
    "        })\n",
    "        return {data: data, sse: sse}\n",
    "    }\n",
    "    \n",
    "    h1 = Math.floor(data.length / 2)\n",
    "    q1 = Math.floor(data.length / 4)\n",
    "    q2 = q1 * 2\n",
    "    q3 = q1 * 3\n",
    "    last = data.length - 1\n",
    "    \n",
    "    alpha = golden_section_search(x => fit(x, 'deseasonalized_adj_qty', 0, last).sse, 0, 1, .01) //alpha optimized on all data\n",
    "    alpha_h1 = golden_section_search(x => fit(x, 'deseasonalized_adj_qty', 0, h1).sse, 0, 1, .01) //alpha optimized for h1\n",
    "    alpha_h2 = golden_section_search(x => fit(x, 'deseasonalized_adj_qty', h1 + 1, last).sse, 0, 1, .01) //etc.\n",
    "    alpha_q1 = golden_section_search(x => fit(x, 'st_deseasonalized_adj_qty', 0, q1).sse, 0, 1, .01) //alpha optimized for q1, using non smoothed seasonal estimate\n",
    "    alpha_q2 = golden_section_search(x => fit(x, 'st_deseasonalized_adj_qty', q1 + 1, q2).sse, 0, 1, .01)\n",
    "    alpha_q3 = golden_section_search(x => fit(x, 'st_deseasonalized_adj_qty', q2 + 1, q3).sse, 0, 1, .01)\n",
    "    alpha_q4 = golden_section_search(x => fit(x, 'st_deseasonalized_adj_qty', q3 + 1, last).sse, 0, 1, .01)\n",
    "    \n",
    "    //fit updates data in place\n",
    "    fit(alpha_h2, 'deseasonalized_adj_qty', 0, 0, 'fcst_deseasonalized_qty', 0, h1) //using alpha optimized for h2 to predict h1\n",
    "    fit(alpha_h1, 'deseasonalized_adj_qty', 0, 0, 'fcst_deseasonalized_qty', h1 + 1, last - 1) //using alpha optimized for h1 to predict h2\n",
    "    fit(alpha, 'deseasonalized_adj_qty', 0, 0, 'fcst_deseasonalized_qty', last, last) //using alpha optimized for all data\n",
    "    fit(alpha_q4, 'st_deseasonalized_adj_qty', 0, 0, 'st_fcst_deseasonalized_qty', 0, last) //use alpha optimized for q4 to predict q1 and last - filling in like this and overwriting below to avoid an extra pass over data\n",
    "    fit(alpha_q1, 'st_deseasonalized_adj_qty', 0, 0, 'st_fcst_deseasonalized_qty', q1 + 1, q2) //using alpha optimized for q1 to predict q2\n",
    "    fit(alpha_q2, 'st_deseasonalized_adj_qty', 0, 0, 'st_fcst_deseasonalized_qty', q2 + 1, q3) //using alpha optimized for q2 to predict q3\n",
    "    fit(alpha_q3, 'st_deseasonalized_adj_qty', 0, 0, 'st_fcst_deseasonalized_qty', q3 + 1, last - 1) //using alpha optimized for q3 to predict q4\n",
    "    \n",
    "    return {data: data, alpha: alpha, alpha_h1: alpha_h1, alpha_h2: alpha_h2, alpha_q1: alpha_q1, alpha_q2: alpha_q2, alpha_q3: alpha_q3, alpha_q4: alpha_q4}\n",
    "    \"\"\";\n",
    "\n",
    "    CREATE OR REPLACE TABLE `genericDataset.BQML_EXP_SMOOTH_OUTPUT` genericTableOptionList AS (\n",
    "    WITH TBL1 AS (\n",
    "    SELECT KEY, EXP_SMOOTH(ARRAY_AGG(STRUCT(DT, DESEASONALIZED_ADJ_QTY, ST_DESEASONALIZED_ADJ_QTY) ORDER BY DT)) AS EXP_SMOOTH_OUTPUT\n",
    "    FROM `genericDataset.BQML_EXP_SMOOTH_DATA`\n",
    "    WHERE FCST_CRT_DT_FLG\n",
    "    GROUP BY 1\n",
    "    )\n",
    "    SELECT A.KEY, B.*, A.EXP_SMOOTH_OUTPUT.* EXCEPT(DATA)\n",
    "    FROM TBL1 A\n",
    "    CROSS JOIN UNNEST(A.EXP_SMOOTH_OUTPUT.DATA) B\n",
    "    );\n",
    "    ''',replaceDict, 'createForecast')\n",
    "    with out:\n",
    "        print(datetime.datetime.now().strftime('%H:%M:%S'), 'Forecast 2 step 7/9 completed...')\n",
    "        print(datetime.datetime.now().strftime('%H:%M:%S'), 'Forecast 3 step 1/3 completed...')\n",
    "\n",
    "    exec_sql('''\n",
    "    CREATE OR REPLACE TABLE `genericDataset.BQML_FCST` genericTableOptionList AS (\n",
    "    SELECT A.KEY\n",
    "        --, A.DT AS FCST_CRT_DT\n",
    "        , A.NEXT_DT AS FCST_CRT_DT\n",
    "        , FCST_DT\n",
    "        , LAG + 1 AS LAG --INDEX STARTS AT 0\n",
    "        , C.QTY\n",
    "        , C.ADJ_QTY\n",
    "        \n",
    "        --LONG TERM FORECAST\n",
    "        , C.DESEASONALIZED_ADJ_QTY\n",
    "        , D.FCST_DESEASONALIZED_QTY\n",
    "        , C.SMOOTHED_SEASONAL_QTY\n",
    "        , D.FCST_DESEASONALIZED_QTY + C.SMOOTHED_SEASONAL_QTY AS FCST_QTY\n",
    "        \n",
    "        --SHORT TERM FORECAST\n",
    "        , C.ST_DESEASONALIZED_ADJ_QTY\n",
    "        , D.ST_FCST_DESEASONALIZED_QTY\n",
    "        , C.SEASONAL_QTY\n",
    "        , D.ST_FCST_DESEASONALIZED_QTY + C.SEASONAL_QTY AS ST_FCST_QTY\n",
    "    FROM `genericDataset.BQML_EXP_SMOOTH_DATA` A\n",
    "    CROSS JOIN UNNEST(A.FCST_DTS) FCST_DT WITH OFFSET LAG\n",
    "    INNER JOIN `genericDataset.BQML_EXP_SMOOTH_DATA` C\n",
    "        ON A.KEY = C.KEY AND FCST_DT = C.DT\n",
    "    INNER JOIN `genericDataset.BQML_EXP_SMOOTH_OUTPUT` D\n",
    "        ON A.KEY = D.KEY AND A.DT = D.DT\n",
    "    WHERE A.FCST_CRT_DT_FLG\n",
    "    );\n",
    "    ''',replaceDict, 'createForecast')\n",
    "    with out:\n",
    "        print(datetime.datetime.now().strftime('%H:%M:%S'), 'Forecast 2 step 8/9 completed...')\n",
    "        print(datetime.datetime.now().strftime('%H:%M:%S'), 'Forecast 3 step 2/3 completed...')\n",
    "\n",
    "    exec_sql('''\n",
    "    UPDATE `genericDataset.genericOutputTable` A\n",
    "    SET A.FORECAST2_genericForecastValue = coalesce( forecastTransform1 B.FCST_QTY forecastTransform2 , 0)\n",
    "        , A.FORECAST3_genericForecastValue = coalesce( forecastTransform1 B.ST_FCST_QTY forecastTransform2, 0)\n",
    "    FROM `genericDataset.BQML_FCST` B\n",
    "    WHERE A.SNPSHT_genericTimePeriod = B.FCST_CRT_DT\n",
    "        AND A.FCST_genericTimePeriod = B.FCST_DT\n",
    "        AND A.AGGLEVEL = B.KEY;\n",
    "    ''',replaceDict, 'createForecast'\n",
    "    ,altSQL='''\n",
    "    UPDATE `genericDataset.genericOutputTable` A\n",
    "    SET A.FORECAST2_genericForecastValue = coalesce( forecastTransform1 B.FCST_QTY forecastTransform2 , 0)\n",
    "        , A.FORECAST3_genericForecastValue = coalesce( forecastTransform1 B.ST_FCST_QTY forecastTransform2, 0)\n",
    "    FROM `genericDataset.BQML_FCST` B\n",
    "    WHERE A.SNPSHT_genericTimePeriod = B.FCST_CRT_DT\n",
    "        AND A.FCST_genericTimePeriod = B.FCST_DT\n",
    "        AND A.AGGLEVEL = B.KEY\n",
    "        AND B.FCST_CRT_DT = date_trunc(current_date(), genericFrequency);--update for current day/week only\n",
    "    '''\n",
    "        )\n",
    "\n",
    "    with out:\n",
    "        print(datetime.datetime.now().strftime('%H:%M:%S'), 'Forecast 2 step 9/9 completed, forecast 2 created successfully.')\n",
    "        print(datetime.datetime.now().strftime('%H:%M:%S'), 'Forecast 3 step 3/3 completed, forecast 3 created successfully.')\n",
    "    #display(Javascript(\"execCellsByTag('Forecast3')\"))\n",
    "\n",
    "except:\n",
    "    with out:\n",
    "        print(datetime.datetime.now().strftime('%H:%M:%S'), 'Error: Invalid input detected while generating forecast 2. Please verify inputs and try again.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "SelectionInput"
    ]
   },
   "outputs": [],
   "source": [
    "#selection logic tables\n",
    "\n",
    "try:\n",
    "    exec_sql(\n",
    "    '''create or replace table `genericDataset.forecast_selection` as (\n",
    "    SELECT snpsht_genericTimePeriod, FCST_genericTimePeriod\n",
    "    , aggLevel\n",
    "    ,actual_genericForecastValue as ACTUAL_genericForecastValue\n",
    "    , greatest(coalesce(forecast1_genericForecastValue,forecast1_genericForecastValue, 0),0) as Forecast1_genericForecastValue\n",
    "    , coalesce(safe_divide(abs(coalesce(forecast1_genericForecastValue,forecast1_genericForecastValue, 0)-Actual_genericForecastValue),(Actual_genericForecastValue)),1.0) as forecast1_MAPE\n",
    "    ,coalesce(Forecast2_genericForecastValue,0) as Forecast2_genericForecastValue\n",
    "    ,coalesce(safe_divide(abs(coalesce(Forecast2_genericForecastValue, forecast2_genericForecastValue,0)-Actual_genericForecastValue),(Actual_genericForecastValue)),1.0) as forecast2_MAPE\n",
    "    ,greatest(forecast3_genericForecastValue,0) as forecast3_genericForecastValue\n",
    "    ,coalesce(safe_divide(abs(coalesce(forecast3_genericForecastValue,0)-Actual_genericForecastValue),(Actual_genericForecastValue)),1.0) as forecast3_MAPE\n",
    "    FROM `genericDataset.genericOutputTable`\n",
    "    where\n",
    "    (fcst_genericTimePeriod = snpsht_genericTimePeriod and\n",
    "    fcst_genericTimePeriod in (SELECT distinct genericTimePeriod From `pr-edw-views-thd.SHARED.CAL_PRD_HIER_FD` where \n",
    "    (select min(fcst_genericTimePeriod) from `genericDataset.genericOutputTable`) <= CAL_DT\n",
    "    and date_trunc(current_date(), genericFrequency) >= CAL_DT))\n",
    "    );\n",
    "    ''',ensembleReplaceDict, 'ensemble')\n",
    "    \n",
    "    with selectionOut:\n",
    "        print(datetime.datetime.now().strftime('%H:%M:%S'), 'Selection logic input table 1/2 completed...')\n",
    "\n",
    "    exec_sql(\n",
    "        '''create or replace table `genericDataset.forecast_stats` genericTableOptionList as (\n",
    "        WITH TBL2A AS (\n",
    "        SELECT A.FCST_genericTimePeriod, B.EVAL_genericTimePeriod\n",
    "        FROM\n",
    "        (\n",
    "        SELECT RANK() OVER (ORDER BY fcst_genericTimePeriod) TIME_RANK, fcst_genericTimePeriod from\n",
    "        (SELECT DISTINCT genericTimePeriod FCST_genericTimePeriod FROM `pr-edw-views-thd.SHARED.CAL_PRD_HIER_FD`\n",
    "        where cal_dt between (select min(genericTimePeriod) from `genericDataset.forecast_data`) and CAST('forecastPeriodEnd' as date))\n",
    "        ORDER BY 1\n",
    "        ) A\n",
    "        INNER JOIN\n",
    "        (\n",
    "        SELECT RANK() OVER (ORDER BY eval_genericTimePeriod) TIME_RANK, eval_genericTimePeriod from\n",
    "        (SELECT DISTINCT genericTimePeriod EVAL_genericTimePeriod FROM `pr-edw-views-thd.SHARED.CAL_PRD_HIER_FD`\n",
    "        where cal_dt between (select min(genericTimePeriod) from `genericDataset.forecast_data`) and date_trunc(current_date(), genericFrequency))\n",
    "        ORDER BY 1\n",
    "        ) B\n",
    "        ON A.TIME_RANK - B.TIME_RANK BETWEEN 1 AND 6--edit time rank to change lag for rolling MAPE\n",
    "        --WHERE\n",
    "        --genericTimePeriod in (SELECT distinct genericTimePeriod From `pr-edw-views-thd.SHARED.CAL_PRD_HIER_FD` where \n",
    "        --CAST(cast('forecastPeriodStart' as string) as date) <= CAL_DT\n",
    "        --and CAST(cast('forecastPeriodEnd' as string) as date) >= CAL_DT)\n",
    "        --and A.TIME_RANK > B.TIME_RANK\n",
    "        --and FLOOR((A.TIME_RANK - B.TIME_RANK) / 52) = 0\n",
    "        ORDER BY 1, 2\n",
    "        )\n",
    "        ,TBL2A_short_period AS (\n",
    "        SELECT A.FCST_genericTimePeriod, B.EVAL_genericTimePeriod\n",
    "        FROM\n",
    "        (\n",
    "        SELECT RANK() OVER (ORDER BY fcst_genericTimePeriod) TIME_RANK, fcst_genericTimePeriod from\n",
    "        (SELECT DISTINCT genericTimePeriod FCST_genericTimePeriod FROM `pr-edw-views-thd.SHARED.CAL_PRD_HIER_FD`\n",
    "        where cal_dt between (select min(genericTimePeriod) from `genericDataset.forecast_data`) and date_trunc(current_date(), genericFrequency))\n",
    "        ORDER BY 1\n",
    "        ) A\n",
    "        INNER JOIN\n",
    "        (\n",
    "        SELECT RANK() OVER (ORDER BY eval_genericTimePeriod) TIME_RANK, eval_genericTimePeriod from\n",
    "        (SELECT DISTINCT genericTimePeriod EVAL_genericTimePeriod FROM `pr-edw-views-thd.SHARED.CAL_PRD_HIER_FD`\n",
    "        where cal_dt between (select min(genericTimePeriod) from `genericDataset.forecast_data`) and date_trunc(current_date(), genericFrequency))\n",
    "        ORDER BY 1\n",
    "        ) B\n",
    "        ON A.TIME_RANK - B.TIME_RANK BETWEEN 1 AND 2--edit time rank to change lag for rolling MAPE\n",
    "        ORDER BY 1, 2\n",
    "        ),\n",
    "        TBL2A_long_period AS (\n",
    "        SELECT A.FCST_genericTimePeriod, B.EVAL_genericTimePeriod\n",
    "        FROM\n",
    "        (\n",
    "        SELECT RANK() OVER (ORDER BY fcst_genericTimePeriod) TIME_RANK, fcst_genericTimePeriod from\n",
    "        (SELECT DISTINCT genericTimePeriod FCST_genericTimePeriod FROM `pr-edw-views-thd.SHARED.CAL_PRD_HIER_FD`\n",
    "        where cal_dt between (select min(genericTimePeriod) from `genericDataset.forecast_data`) and date_trunc(current_date(), genericFrequency))\n",
    "        ORDER BY 1\n",
    "        ) A\n",
    "        INNER JOIN\n",
    "        (\n",
    "        SELECT RANK() OVER (ORDER BY eval_genericTimePeriod) TIME_RANK, eval_genericTimePeriod from\n",
    "        (SELECT DISTINCT genericTimePeriod EVAL_genericTimePeriod FROM `pr-edw-views-thd.SHARED.CAL_PRD_HIER_FD`\n",
    "        where cal_dt between (select min(genericTimePeriod) from `genericDataset.forecast_data`) and date_trunc(current_date(), genericFrequency))\n",
    "        ORDER BY 1\n",
    "        ) B\n",
    "        ON A.TIME_RANK - B.TIME_RANK BETWEEN 1 AND 52--edit time rank to change lag for rolling MAPE\n",
    "        ORDER BY 1, 2\n",
    "        ),\n",
    "        avg_mape as (\n",
    "        select fcst_genericTimePeriod, aggLevel\n",
    "        , avg(forecast1_mape) as avg_forecast1_mape, stddev(forecast1_mape) as stddev_forecast1_mape\n",
    "        , avg(forecast2_mape) as avg_forecast2_mape, stddev(forecast2_mape) as stddev_forecast2_mape\n",
    "        , avg(forecast3_mape) as avg_forecast3_mape, stddev(forecast3_mape) as stddev_forecast3_mape\n",
    "        from\n",
    "        (select a.*, b.* except (FCST_genericTimePeriod) from TBL2A a\n",
    "        inner join `genericDataset.forecast_selection` b\n",
    "        on a.eval_genericTimePeriod = b.FCST_genericTimePeriod) c\n",
    "        where aggLevel is not null\n",
    "        group by 1,2\n",
    "        union all\n",
    "        select * from\n",
    "        (select min(fcst_genericTimePeriod) from `genericDataset.forecast_selection`)\n",
    "        cross join\n",
    "        (select distinct aggLevel, null, null, null, null, null, null--, null, null\n",
    "        from `genericDataset.forecast_selection`)\n",
    "        ),\n",
    "        avg_mape_short as (\n",
    "        select fcst_genericTimePeriod, aggLevel\n",
    "        , avg(forecast1_mape) as avg_forecast1_mape_short, stddev(forecast1_mape) as stddev_forecast1_mape_short\n",
    "        , avg(forecast2_mape) as avg_forecast2_mape_short, stddev(forecast2_mape) as stddev_forecast2_mape_short\n",
    "        , avg(forecast3_mape) as avg_forecast3_mape_short, stddev(forecast3_mape) as stddev_forecast3_mape_short\n",
    "        from\n",
    "        (select a.*, b.* except (FCST_genericTimePeriod) from TBL2A_short_period a\n",
    "        inner join `genericDataset.forecast_selection` b\n",
    "        on a.eval_genericTimePeriod = b.FCST_genericTimePeriod) c\n",
    "        group by 1,2\n",
    "        union all\n",
    "        select * from\n",
    "        (select min(fcst_genericTimePeriod) from `genericDataset.forecast_selection`)\n",
    "        cross join\n",
    "        (select distinct aggLevel, null, null, null, null, null, null--, null, null\n",
    "        from `genericDataset.forecast_selection`)\n",
    "        ),\n",
    "        avg_mape_long as (\n",
    "        select fcst_genericTimePeriod, aggLevel\n",
    "        , avg(forecast1_mape) as overall_avg_forecast1_mape, stddev(forecast1_mape) as overall_stddev_forecast1_mape\n",
    "        , avg(forecast2_mape) as overall_avg_forecast2_mape, stddev(forecast2_mape) as overall_stddev_forecast2_mape\n",
    "        , avg(forecast3_mape) as overall_avg_forecast3_mape, stddev(forecast3_mape) as overall_stddev_forecast3_mape\n",
    "        from\n",
    "        (select a.*, b.* except (FCST_genericTimePeriod) from TBL2A_long_period a\n",
    "        inner join `genericDataset.forecast_selection` b\n",
    "        on a.eval_genericTimePeriod = b.FCST_genericTimePeriod) c\n",
    "        where aggLevel is not null\n",
    "        group by 1,2\n",
    "        union all\n",
    "        select * from\n",
    "        (select min(fcst_genericTimePeriod) from `genericDataset.forecast_selection`)\n",
    "        cross join\n",
    "        (select distinct aggLevel, null, null, null, null, null, null--, null, null\n",
    "        from `genericDataset.forecast_selection`)\n",
    "        ),\n",
    "        forecast_stats AS\n",
    "        (\n",
    "        select a.fcst_genericTimePeriod, a.aggLevel\n",
    "        ,d.actual_genericForecastValue, forecast1_genericForecastValue\n",
    "        ,forecast2_genericForecastValue, forecast3_genericForecastValue\n",
    "        ,forecast1_mape\n",
    "        ,forecast2_mape\n",
    "        ,forecast3_mape\n",
    "        ,case\n",
    "        when forecast1_mape > forecast2_mape and forecast3_mape > forecast2_mape\n",
    "        and forecast2_mape is not null\n",
    "        then \"forecast2\"\n",
    "        when forecast2_mape > forecast3_mape and forecast1_mape > forecast3_mape\n",
    "        and forecast3_mape is not null\n",
    "        then \"forecast3\"\n",
    "        when forecast2_mape > forecast1_mape and forecast3_mape > forecast1_mape\n",
    "        then \"forecast1\"\n",
    "        else \"Default - FORECAST2\" end as best_forecast\n",
    "        ,least(avg_forecast1_mape/*, avg_fin_mape, avg_is_mape, avg_nm_mape*/, avg_forecast2_mape, avg_forecast3_mape) as least_avg_mape\n",
    "        ,least(avg_forecast1_mape_short/*, avg_fin_mape_short, avg_is_mape_short, avg_nm_mape_short*/, avg_forecast2_mape_short, avg_forecast3_mape_short) as least_avg_mape_short\n",
    "        ,least(overall_avg_forecast1_mape, overall_avg_forecast2_mape/*, overall_avg_is_mape, overall_avg_nm_mape*/, overall_avg_forecast3_mape) as overall_least_avg_mape\n",
    "        ,least(stddev_forecast1_mape, stddev_forecast2_mape/*, stddev_is_mape, stddev_nm_mape*/, stddev_forecast3_mape) as least_stddev_mape\n",
    "        ,least(overall_stddev_forecast1_mape,overall_stddev_forecast2_mape/*, overall_stddev_is_mape, overall_stddev_nm_mape*/, overall_stddev_forecast3_mape) as overall_least_stddev_mape\n",
    "        ,coalesce(avg_forecast1_mape,1) as avg_forecast1_mape,coalesce(overall_avg_forecast1_mape,1) as overall_avg_forecast1_mape,coalesce(avg_forecast1_mape_short,1) as avg_forecast1_mape_short\n",
    "        ,coalesce(stddev_forecast1_mape,0) as stddev_forecast1_mape,coalesce(overall_stddev_forecast1_mape,0) as overall_stddev_forecast1_mape\n",
    "        ,coalesce(avg_forecast2_mape,1) as avg_forecast2_mape,coalesce(overall_avg_forecast2_mape,1) as overall_avg_forecast2_mape,coalesce(avg_forecast2_mape_short,1) as avg_forecast2_mape_short\n",
    "        ,coalesce(stddev_forecast2_mape,0) as stddev_forecast2_mape,coalesce(overall_stddev_forecast2_mape,0) as overall_stddev_forecast2_mape\n",
    "        ,coalesce(avg_forecast3_mape,1) as avg_forecast3_mape,coalesce(overall_avg_forecast3_mape,1) as overall_avg_forecast3_mape,coalesce(avg_forecast3_mape_short,1) as avg_forecast3_mape_short\n",
    "        ,coalesce(stddev_forecast3_mape,0) as stddev_forecast3_mape,coalesce(overall_stddev_forecast3_mape,0) as overall_stddev_forecast3_mape\n",
    "        , e.time_rank\n",
    "        from avg_mape a\n",
    "        inner join avg_mape_long b\n",
    "        on a.fcst_genericTimePeriod = b.fcst_genericTimePeriod\n",
    "        and a.aggLevel = b.aggLevel\n",
    "        inner join avg_mape_short c\n",
    "        on a.fcst_genericTimePeriod = c.fcst_genericTimePeriod\n",
    "        and a.aggLevel = c.aggLevel\n",
    "        inner join `genericDataset.forecast_selection` d\n",
    "        on a.fcst_genericTimePeriod = d.fcst_genericTimePeriod\n",
    "        and a.aggLevel = d.aggLevel\n",
    "        inner join\n",
    "        (SELECT DISTINCT RANK() OVER (ORDER BY FCST_genericTimePeriod) TIME_RANK, fcst_genericTimePeriod from (select distinct FCST_genericTimePeriod FROM `genericDataset.forecast_selection`)\n",
    "        ORDER BY 1) e\n",
    "        on a.fcst_genericTimePeriod = e.fcst_genericTimePeriod\n",
    "        )\n",
    "\n",
    "\n",
    "        select a.best_forecast as prev_best_forecast, b.*\n",
    "        , b.avg_forecast1_mape - b.least_avg_mape as least_avg_forecast1_mape\n",
    "        , b.avg_forecast2_mape - b.least_avg_mape as least_avg_forecast2_mape\n",
    "        , b.avg_forecast3_mape - b.least_avg_mape as least_avg_forecast3_mape\n",
    "        , b.avg_forecast1_mape_short - b.least_avg_mape_short as least_avg_forecast1_mape_short\n",
    "        , b.avg_forecast2_mape_short - b.least_avg_mape_short as least_avg_forecast2_mape_short\n",
    "        , b.avg_forecast3_mape_short - b.least_avg_mape_short as least_avg_forecast3_mape_short\n",
    "        , b.overall_avg_forecast1_mape - b.overall_least_avg_mape as overall_least_avg_forecast1_mape\n",
    "        , b.overall_avg_forecast2_mape - b.overall_least_avg_mape as overall_least_avg_forecast2_mape\n",
    "        , b.overall_avg_forecast3_mape - b.overall_least_avg_mape as overall_least_avg_forecast3_mape\n",
    "        , b.stddev_forecast1_mape - b.least_stddev_mape as least_stddev_forecast1_mape\n",
    "        , b.stddev_forecast2_mape - b.least_stddev_mape as least_stddev_forecast2_mape\n",
    "        , b.stddev_forecast3_mape - b.least_stddev_mape as least_stddev_forecast3_mape\n",
    "        , b.overall_stddev_forecast1_mape - b.overall_least_stddev_mape as overall_least_stddev_forecast1_mape\n",
    "        , b.overall_stddev_forecast2_mape - b.overall_least_stddev_mape as overall_least_stddev_forecast2_mape\n",
    "        , b.overall_stddev_forecast3_mape - b.overall_least_stddev_mape as overall_least_stddev_forecast3_mape\n",
    "        from forecast_stats a\n",
    "        right join forecast_stats b\n",
    "        on b.time_rank - a.time_rank = 1\n",
    "        and a.aggLevel = b.aggLevel\n",
    "        );\n",
    "    ''',ensembleReplaceDict, 'ensemble')\n",
    "\n",
    "    \n",
    "    with selectionOut:\n",
    "        print(datetime.datetime.now().strftime('%H:%M:%S'), 'Selection logic input table 2/2 completed...')\n",
    "    \n",
    "except:\n",
    "    with selectionOut:\n",
    "        print(datetime.datetime.now().strftime('%H:%M:%S'), 'Error: Invalid input detected while generating selection input tables. Please verify inputs and try again.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "RulesSelection"
    ]
   },
   "outputs": [],
   "source": [
    "#rules based selection\n",
    "\n",
    "try:\n",
    "    exec_sql(\n",
    "    '''\n",
    "    create or replace table `genericDataset.one_selection` genericTableOptionList as (\n",
    "\n",
    "    with pre_one_selection as (\n",
    "    select\n",
    "    coalesce(\n",
    "    case\n",
    "    when \n",
    "    least(least_avg_forecast1_mape, least_avg_forecast2_mape, least_avg_forecast3_mape) = least_avg_forecast2_mape\n",
    "    and (least_avg_forecast1_mape = least_avg_forecast2_mape or least_avg_forecast2_mape = least_avg_forecast3_mape)\n",
    "    then forecast2_genericForecastValue\n",
    "    when\n",
    "    least(least_avg_forecast1_mape, least_avg_forecast2_mape, least_avg_forecast3_mape) = least_avg_forecast3_mape\n",
    "    and (least_avg_forecast1_mape = least_avg_forecast3_mape)\n",
    "    then coalesce(forecast1_genericForecastValue, 0)\n",
    "    when least(least_avg_forecast1_mape, least_avg_forecast2_mape, least_avg_forecast3_mape)\n",
    "    = least_avg_forecast2_mape then forecast2_genericForecastValue \n",
    "    when least(least_avg_forecast1_mape, least_avg_forecast2_mape, least_avg_forecast3_mape)\n",
    "    = least_avg_forecast3_mape then coalesce(forecast3_genericForecastValue,0)\n",
    "    when least(least_avg_forecast1_mape, least_avg_forecast2_mape, least_avg_forecast3_mape)\n",
    "    = least_avg_forecast1_mape then coalesce(forecast1_genericForecastValue,0)\n",
    "    end,0)\n",
    "    as one_genericForecastValue\n",
    "    ,case\n",
    "    when \n",
    "    least(least_avg_forecast1_mape, least_avg_forecast2_mape, least_avg_forecast3_mape) = least_avg_forecast2_mape\n",
    "    and (least_avg_forecast1_mape = least_avg_forecast2_mape or least_avg_forecast2_mape = least_avg_forecast3_mape)\n",
    "    then 'Default - Forecast2' \n",
    "    when \n",
    "    least(least_avg_forecast1_mape, least_avg_forecast2_mape, least_avg_forecast3_mape) = least_avg_forecast3_mape\n",
    "    and (least_avg_forecast1_mape = least_avg_forecast3_mape)\n",
    "    then 'Default - Forecast1'\n",
    "    when least(least_avg_forecast1_mape, least_avg_forecast2_mape, least_avg_forecast3_mape)\n",
    "    = least_avg_forecast2_mape then 'Forecast2' \n",
    "    when least(least_avg_forecast1_mape, least_avg_forecast2_mape, least_avg_forecast3_mape)\n",
    "    = least_avg_forecast3_mape then 'Forecast3'\n",
    "    when least(least_avg_forecast1_mape, least_avg_forecast2_mape, least_avg_forecast3_mape)\n",
    "    = least_avg_forecast1_mape then 'Forecast1'\n",
    "    end as one_selection\n",
    "    ,actual_genericForecastValue\n",
    "    ,forecast1_genericForecastValue\n",
    "    ,forecast2_genericForecastValue\n",
    "    ,forecast3_genericForecastValue\n",
    "    ,fcst_genericTimePeriod\n",
    "    ,aggLevel\n",
    "    , least_avg_forecast1_mape, least_avg_forecast2_mape, least_avg_forecast3_mape\n",
    "    , case\n",
    "    when least(abs(forecast1_genericForecastValue - coalesce(actual_genericForecastValue,0))\n",
    "    ,abs(forecast3_genericForecastValue - coalesce(actual_genericForecastValue,0))\n",
    "    ,abs(forecast2_genericForecastValue - coalesce(actual_genericForecastValue,0))) = abs(forecast2_genericForecastValue - coalesce(actual_genericForecastValue,0)) then forecast2_genericForecastValue\n",
    "    when least(abs(forecast1_genericForecastValue - coalesce(actual_genericForecastValue,0))\n",
    "    ,abs(forecast3_genericForecastValue - coalesce(actual_genericForecastValue,0))\n",
    "    ,abs(forecast2_genericForecastValue - coalesce(actual_genericForecastValue,0))) = abs(forecast1_genericForecastValue - coalesce(actual_genericForecastValue,0)) then forecast1_genericForecastValue\n",
    "    when least(abs(forecast1_genericForecastValue - coalesce(actual_genericForecastValue,0))\n",
    "    ,abs(forecast3_genericForecastValue - coalesce(actual_genericForecastValue,0))\n",
    "    ,abs(forecast2_genericForecastValue - coalesce(actual_genericForecastValue,0))) = abs(forecast3_genericForecastValue - coalesce(actual_genericForecastValue,0)) then forecast3_genericForecastValue\n",
    "    end as best_genericForecastValue\n",
    "    from\n",
    "    `genericDataset.forecast_stats`\n",
    "    where current_date() >= fcst_genericTimePeriod\n",
    "    ),\n",
    "    recent_best as (\n",
    "    select aggLevel, one_selection, least_avg_forecast1_mape, least_avg_forecast2_mape, least_avg_forecast3_mape from pre_one_selection\n",
    "    where fcst_genericTimePeriod = (SELECT max(genericTimePeriod) FROM `pr-edw-views-thd.SHARED.CAL_PRD_HIER_FD` where \n",
    "    current_date() >= FSCL_WK_BGN_DT\n",
    "    and current_date() <= FSCL_WK_END_DT)\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    --selection for 6 weeks from current week\n",
    "    select * from pre_one_selection\n",
    "    union all\n",
    "    select\n",
    "    coalesce(case \n",
    "    when \n",
    "    least(least_avg_forecast1_mape, least_avg_forecast2_mape, least_avg_forecast3_mape) = least_avg_forecast2_mape\n",
    "    and (least_avg_forecast1_mape = least_avg_forecast2_mape or least_avg_forecast2_mape = least_avg_forecast3_mape)\n",
    "    then a.forecast2_genericForecastValue\n",
    "    when \n",
    "    least(least_avg_forecast1_mape, least_avg_forecast2_mape, least_avg_forecast3_mape) = least_avg_forecast3_mape\n",
    "    and (least_avg_forecast1_mape = least_avg_forecast3_mape)\n",
    "    then coalesce(b.forecast3_genericForecastValue, 0)\n",
    "    when least(least_avg_forecast1_mape, least_avg_forecast2_mape, least_avg_forecast3_mape)\n",
    "    = least_avg_forecast2_mape then a.forecast2_genericForecastValue \n",
    "    when least(least_avg_forecast1_mape, least_avg_forecast2_mape, least_avg_forecast3_mape)\n",
    "    = least_avg_forecast3_mape then coalesce(b.forecast3_genericForecastValue,0)\n",
    "    when least(least_avg_forecast1_mape, least_avg_forecast2_mape, least_avg_forecast3_mape)\n",
    "    = least_avg_forecast1_mape then coalesce(a.forecast1_genericForecastValue,0)\n",
    "    end,0) as one_genericForecastValue\n",
    "    ,c.one_selection\n",
    "    ,a.actual_genericForecastValue\n",
    "    ,coalesce(a.forecast1_genericForecastValue,0) as forecast1_genericForecastValue\n",
    "    ,coalesce(a.forecast2_genericForecastValue,0) as forecast2_genericForecastValue\n",
    "    ,coalesce(b.forecast3_genericForecastValue,0) as forecast3_genericForecastValue\n",
    "    ,a.fcst_genericTimePeriod\n",
    "    ,a.aggLevel\n",
    "    ,null,null,null,null\n",
    "    from\n",
    "    `genericDataset.genericOutputTable` a\n",
    "    ,`genericDataset.genericOutputTable` b\n",
    "    ,recent_best c\n",
    "    where a.fcst_genericTimePeriod >= (SELECT max(genericTimePeriod) FROM `pr-edw-views-thd.SHARED.CAL_PRD_HIER_FD` where \n",
    "    current_date() >= FSCL_WK_BGN_DT\n",
    "    and current_date() <= FSCL_WK_END_DT)\n",
    "    and a.snpsht_genericTimePeriod = (SELECT max(genericTimePeriod) FROM `pr-edw-views-thd.SHARED.CAL_PRD_HIER_FD` where \n",
    "    current_date() >= FSCL_WK_BGN_DT\n",
    "    and current_date() <= FSCL_WK_END_DT)\n",
    "    and a.aggLevel = b.aggLevel\n",
    "    and a.aggLevel = c.aggLevel\n",
    "    and a.fcst_genericTimePeriod = b.snpsht_genericTimePeriod\n",
    "    and b.fcst_genericTimePeriod = b.snpsht_genericTimePeriod\n",
    "    );\n",
    "    ''',ensembleReplaceDict, 'ensemble')\n",
    "\n",
    "    \n",
    "    exec_sql(\n",
    "    ''' update `genericDataset.genericOutputTable` a\n",
    "        set a.one_forecast_genericForecastValue  =\n",
    "        case\n",
    "        when \n",
    "        least(least_avg_forecast1_mape, least_avg_forecast2_mape, least_avg_forecast3_mape) = least_avg_forecast2_mape\n",
    "        and (least_avg_forecast1_mape = least_avg_forecast2_mape or least_avg_forecast2_mape = least_avg_forecast3_mape)\n",
    "        then a.forecast2_genericForecastValue\n",
    "        when \n",
    "        least(least_avg_forecast1_mape, least_avg_forecast2_mape, least_avg_forecast3_mape) = least_avg_forecast3_mape\n",
    "        and (least_avg_forecast1_mape = least_avg_forecast3_mape)\n",
    "        then a.forecast1_genericForecastValue\n",
    "        when least(least_avg_forecast1_mape, least_avg_forecast2_mape, least_avg_forecast3_mape)\n",
    "        = least_avg_forecast2_mape then a.forecast2_genericForecastValue\n",
    "        when least(least_avg_forecast1_mape, least_avg_forecast2_mape, least_avg_forecast3_mape)\n",
    "        = least_avg_forecast3_mape then a.forecast3_genericForecastValue\n",
    "        when least(least_avg_forecast1_mape, least_avg_forecast2_mape, least_avg_forecast3_mape)\n",
    "        = least_avg_forecast1_mape then a.forecast1_genericForecastValue\n",
    "        end\n",
    "        FROM `genericDataset.one_selection` b\n",
    "        where a.snpsht_genericTimePeriod = b.fcst_genericTimePeriod\n",
    "        and a.aggLevel = b.aggLevel;\n",
    "    ''',ensembleReplaceDict, 'ensemble'\n",
    "    ,altSQL='''update `genericDataset.genericOutputTable` a\n",
    "        set a.one_forecast_genericForecastValue  =\n",
    "        case\n",
    "        when\n",
    "        least(least_avg_forecast1_mape, least_avg_forecast2_mape, least_avg_forecast3_mape) = least_avg_forecast2_mape\n",
    "        and (least_avg_forecast1_mape = least_avg_forecast2_mape or least_avg_forecast2_mape = least_avg_forecast3_mape)\n",
    "        then a.forecast2_genericForecastValue\n",
    "        when \n",
    "        least(least_avg_forecast1_mape, least_avg_forecast2_mape, least_avg_forecast3_mape) = least_avg_forecast3_mape\n",
    "        and (least_avg_forecast1_mape = least_avg_forecast3_mape)\n",
    "        then a.forecast1_genericForecastValue\n",
    "        when least(least_avg_forecast1_mape, least_avg_forecast2_mape, least_avg_forecast3_mape)\n",
    "        = least_avg_forecast2_mape then a.forecast2_genericForecastValue\n",
    "        when least(least_avg_forecast1_mape, least_avg_forecast2_mape, least_avg_forecast3_mape)\n",
    "        = least_avg_forecast3_mape then a.forecast3_genericForecastValue\n",
    "        when least(least_avg_forecast1_mape, least_avg_forecast2_mape, least_avg_forecast3_mape)\n",
    "        = least_avg_forecast1_mape then a.forecast1_genericForecastValue\n",
    "        end\n",
    "        FROM `genericDataset.one_selection` b\n",
    "        where a.snpsht_genericTimePeriod = b.fcst_genericTimePeriod\n",
    "        and a.snpsht_genericTimePeriod = date_trunc(current_date(), genericFrequency)\n",
    "        and a.aggLevel = b.aggLevel;'''\n",
    "    )\n",
    "    \n",
    "    with selectionOut:\n",
    "        print(datetime.datetime.now().strftime('%H:%M:%S'), genericReplace('Rules based selection output stored in `genericDataset.genericOutputTable`. Forecast process complete.',replaceDict))\n",
    "except:\n",
    "    with selectionOut:\n",
    "        print(datetime.datetime.now().strftime('%H:%M:%S'), 'Error: Invalid input detected while generating rules based selection. Please verify inputs and try again.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "RLSelection"
    ]
   },
   "outputs": [],
   "source": [
    "#RL selection\n",
    "\n",
    "try:\n",
    "    exec_sql(\n",
    "    '''CREATE OR REPLACE FUNCTION  `genericDataset.learn`(history ARRAY<STRUCT<fcst_genericTimePeriod DATE, ONE_MAPE FLOAT64\n",
    "        , least_avg_forecast1_mape FLOAT64, least_avg_forecast2_mape FLOAT64, least_avg_forecast3_mape FLOAT64\n",
    "        , forecast1_genericForecastValue FLOAT64, forecast2_genericForecastValue FLOAT64, forecast3_genericForecastValue FLOAT64, actual_genericForecastValue FLOAT64\n",
    "        ,forecast1_MAPE FLOAT64, forecast2_MAPE FLOAT64, forecast3_MAPE FLOAT64, Min_MAPE FLOAT64, Max_MAPE FLOAT64>>)\n",
    "        RETURNS ARRAY<STRUCT<fcst_genericTimePeriod DATE, ONE_QTY FLOAT64, forecast1_QTY FLOAT64, forecast2_QTY FLOAT64, forecast3_QTY FLOAT64, ACTUAL_QTY FLOAT64\n",
    "        , ONE_MAPE FLOAT64, forecast1_MAPE FLOAT64, forecast2_MAPE FLOAT64, forecast3_MAPE FLOAT64, FORECAST_CHOSEN STRING, reward FLOAT64>> LANGUAGE js\n",
    "    OPTIONS (library=[\"JSCloudPath/rl.js\"]) AS \"\"\"\n",
    "            var states = []//array of states\n",
    "            var actualMAPE = []//array of periodly MAPE values\n",
    "            var qty = []//array of each forecasts periodly qty\n",
    "            var genericTimePeriod = []//array of fscl periods\n",
    "            var data = history.map(function(obj) {\n",
    "              return Object.keys(obj).map(function(key) {\n",
    "                return obj[key]\n",
    "              })\n",
    "            })\n",
    "            var i = 0\n",
    "            while(i < data.length) {\n",
    "                states.push(data[i].slice(1,5))\n",
    "                actualMAPE.push(data[i].slice(9))\n",
    "                qty.push(data[i].slice(5,9))\n",
    "                genericTimePeriod.push(data[i][0])\n",
    "                i++\n",
    "            }\n",
    "\n",
    "            var env = {}\n",
    "            env.getNumStates = function() { return 4 }//One, FORECAST1, FORECAST2, FORECAST3 MAPE values\n",
    "            env.getMaxNumActions = function() { return 3 }//action is forecast chosen for next period\n",
    "            //0 = FORECAST1, 1 = FORECAST2, 2 = FORECAST3\n",
    "\n",
    "            // create the DQN agent\n",
    "            //need to take experience size \n",
    "            var numPeriods = genericTimePeriod.length\n",
    "            var spec = { alpha: 0.1, experience_size: numPeriods * .2, experience_add_every: 1, epsilon: 1, gamma: 0, learning_steps_per_iteration: 10 } // see full options on DQN page\n",
    "            //test different options for alpha and epsilon\n",
    "            //Gamma = 1 = max greediness, does not consider potential applications from future states\n",
    "            agent = new RL.DQNAgent(env, spec)\n",
    "            var selectedMAPE = []\n",
    "            var forecast = []\n",
    "            var period = 0\n",
    "            while(period < numPeriods)\n",
    "            {\n",
    "                agent.epsilon = 1 - (period)/(numPeriods * .8)\n",
    "\n",
    "                if (period > numPeriods * .8) {//stop exploring before last year\n",
    "                    agent.epsilon = 0\n",
    "                }\n",
    "                var state = states[period]//set state\n",
    "                if (period > 0) {\n",
    "                    //console.log(state[period][0])\n",
    "                    state[0] = selectedMAPE[period - 1]//update ONE MAPE value of state to be MAPE of forecast selected LAST PERIOD\n",
    "                } else {\n",
    "                    state[0] = 1//what should default be?\n",
    "                }\n",
    "                var action = agent.act(state) // s is an array of length NumStates ... execute action in environment and get the reward\n",
    "\n",
    "                //states[period][0] = actualMAPE[period][action]//update state with least MAPE calculation mape for next period from chosen action\n",
    "                selectedMAPE.push(actualMAPE[period][action])\n",
    "                //update s1 which is updated based on action in agent.act\n",
    "                var selection = [\"forecast1\",\"forecast2\",\"forecast3\"]\n",
    "                var reward = 1 - ((actualMAPE[period][action] - actualMAPE[period][3])/(actualMAPE[period][4]-actualMAPE[period][3]))//1 - (selected MAPE - lowest MAPE) / (highest MAPE - lowest MAPE)\n",
    "                if (actualMAPE[period][0] == actualMAPE[period][1] && actualMAPE[period][0] == actualMAPE[period][2]) {\n",
    "                    reward = 0\n",
    "                    //reward = 100 * actualMAPE[period][action]\n",
    "                }\n",
    "                else if (reward > .5) {\n",
    "                    reward *= 100 * (actualMAPE[period][4]-actualMAPE[period][3])//scale by difference between max and min\n",
    "                    reward = Math.min(reward, 100)\n",
    "                } else {\n",
    "                    reward = -100 * (1-reward) * (actualMAPE[period][4]-actualMAPE[period][3])\n",
    "                    reward = Math.max(reward, -100)\n",
    "                }\n",
    "                agent.learn(reward) // the agent improves its Q,policy,model, etc. reward is a float, also randomly samples an experience from memory\n",
    "\n",
    "                //generate output\n",
    "                if (!qty[period][3]) {//don't calculate MAPE if actuals are null\n",
    "                    forecast.push({fcst_genericTimePeriod:genericTimePeriod[period],ONE_QTY:qty[period][action], forecast1_QTY:qty[period][0], forecast2_QTY:qty[period][1], forecast3_QTY:qty[period][2]\n",
    "                        ,ACTUAL_QTY:qty[period][3]\n",
    "                        ,FORECAST_CHOSEN:selection[action]\n",
    "                        ,reward:reward}\n",
    "                    )\n",
    "                } else {\n",
    "                    forecast.push({fcst_genericTimePeriod:genericTimePeriod[period],ONE_QTY:qty[period][action], forecast1_QTY:qty[period][0], forecast2_QTY:qty[period][1], forecast3_QTY:qty[period][2]\n",
    "                        ,ACTUAL_QTY:qty[period][3]\n",
    "                        ,ONE_MAPE:(Math.abs(qty[period][action] - qty[period][3])/qty[period][3]).toFixed(4)\n",
    "                        ,forecast1_MAPE:(Math.abs(qty[period][0] - qty[period][3])/qty[period][3]).toFixed(4)\n",
    "                        ,forecast2_MAPE:(Math.abs(qty[period][1] - qty[period][3])/qty[period][3]).toFixed(4)\n",
    "                        ,forecast3_MAPE:(Math.abs(qty[period][2] - qty[period][3])/qty[period][3]).toFixed(4)\n",
    "                        ,FORECAST_CHOSEN:selection[action]\n",
    "                        ,reward:reward}\n",
    "                    )\n",
    "                }\n",
    "\n",
    "                period++\n",
    "          }\n",
    "          return forecast\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\";\n",
    "    ''',ensembleReplaceDict, 'ensemble')\n",
    "\n",
    "\n",
    "\n",
    "    # call persistent UDF reinforcement learning model to select the best forecast each period\n",
    "    # state: 6 wk rolling error for each of the three forecasts\n",
    "    # action: pick one of the three forecasts\n",
    "    # reward: positive value for below average error selection, negative value for above average error selection\n",
    "    exec_sql(\n",
    "    '''\n",
    "    create or replace table `genericDataset.RL_output` as (\n",
    "    select aggLevel, b.* from\n",
    "    (select aggLevel, `genericDataset.learn`(ARRAY_AGG(STRUCT(fcst_genericTimePeriod, 0.0 as ONE_MAPE, least_avg_forecast1_MAPE, least_avg_forecast2_MAPE\n",
    "    ,least_avg_forecast3_MAPE\n",
    "    ,forecast1_genericForecastValue, forecast2_genericForecastValue, forecast3_genericForecastValue, cast( actual_genericForecastValue as float64)\n",
    "    ,forecast1_mape, forecast2_mape, forecast3_mape\n",
    "    ,least(forecast1_mape, forecast2_mape,forecast3_mape) as min_mape\n",
    "    ,greatest(forecast1_mape, forecast2_mape, forecast3_mape) as max_mape) order by fcst_genericTimePeriod)) as RL_OUTPUT\n",
    "    FROM `genericDataset.forecast_stats`\n",
    "    where fcst_genericTimePeriod <= current_date()\n",
    "    \n",
    "    group by 1) a\n",
    "    --having count(*) = (select count(distinct fcst_genericTimePeriod) from `genericDataset.forecast_stats` where fcst_genericTimePeriod <= current_date())) a\n",
    "    ,unnest(RL_OUTPUT) b\n",
    "    );\n",
    "    ''',ensembleReplaceDict, 'ensemble'\n",
    "    ,altSQL=\n",
    "    '''create or replace table `genericDataset.RL_output` genericTableOptionList as (\n",
    "    with tbl1 as (\n",
    "    select aggLevel, b.* from\n",
    "    (select aggLevel, `genericDataset.learn`(ARRAY_AGG(STRUCT(fcst_genericTimePeriod, 0.0 as ONE_MAPE, least_avg_forecast1_MAPE, least_avg_forecast2_MAPE\n",
    "    ,least_avg_forecast3_MAPE\n",
    "    ,forecast1_genericForecastValue, forecast2_genericForecastValue, forecast3_genericForecastValue, cast( actual_genericForecastValue as float64)\n",
    "    ,forecast1_mape, forecast2_mape, forecast3_mape\n",
    "    ,least(forecast1_mape, forecast2_mape,forecast3_mape) as min_mape\n",
    "    ,greatest(forecast1_mape, forecast2_mape, forecast3_mape) as max_mape) order by fcst_genericTimePeriod)) as RL_OUTPUT\n",
    "    FROM `genericDataset.forecast_stats`\n",
    "    where fcst_genericTimePeriod <= current_date()\n",
    "    \n",
    "    group by 1) a\n",
    "    --having count(*) = (select count(distinct fcst_genericTimePeriod) from `genericDataset.forecast_stats` where fcst_genericTimePeriod <= current_date())) a\n",
    "    ,unnest(RL_OUTPUT) b\n",
    "    )\n",
    "    \n",
    "    select * from `genericDataset.RL_output`\n",
    "    union distinct\n",
    "    select * from tbl1\n",
    "    where fcst_genericTimePeriod >= (select max(fcst_genericTimePeriod) from `genericDataset.RL_output`)\n",
    "    and fcst_genericTimePeriod <= current_date()\n",
    "    \n",
    "    );'''\n",
    "    \n",
    "    )\n",
    "\n",
    "    exec_sql(\n",
    "    ''' update `genericDataset.genericOutputTable` a\n",
    "        set a.one_forecast_genericForecastValue  =\n",
    "        case\n",
    "        when b.forecast_chosen = 'forecast1'\n",
    "        then b.forecast1_genericForecastValue\n",
    "        when b.forecast_chosen = 'forecast2'\n",
    "        then b.forecast2_genericForecastValue\n",
    "        when b.forecast_chosen = 'forecast3'\n",
    "        then b.forecast3_genericForecastValue\n",
    "        end\n",
    "        FROM `genericDataset.RL_output` b\n",
    "        where a.snpsht_genericTimePeriod = b.fcst_genericTimePeriod\n",
    "        and a.aggLevel = b.aggLevel;\n",
    "    ''',ensembleReplaceDict, 'ensemble'\n",
    "    ,altSQL = ''' update `genericDataset.genericOutputTable` a\n",
    "        set a.one_forecast_genericForecastValue  =\n",
    "        case\n",
    "        when b.forecast_chosen = 'forecast1'\n",
    "        then b.forecast1_genericForecastValue\n",
    "        when b.forecast_chosen = 'forecast2'\n",
    "        then b.forecast2_genericForecastValue\n",
    "        when b.forecast_chosen = 'forecast3'\n",
    "        then b.forecast3_genericForecastValue\n",
    "        end\n",
    "        FROM `genericDataset.RL_output` b\n",
    "        where a.snpsht_genericTimePeriod = b.fcst_genericTimePeriod\n",
    "        and a.snpsht_genericTimePeriod = date_trunc(current_date(), genericFrequency)\n",
    "        and a.aggLevel = b.aggLevel;\n",
    "    ''')\n",
    "\n",
    "    with selectionOut:\n",
    "        print(datetime.datetime.now().strftime('%H:%M:%S'), genericReplace('Reinforcement Learning selection output stored in `genericDataset.genericOutputTable`. Forecast process complete.',replaceDict))\n",
    "except:\n",
    "    with selectionOut:\n",
    "        print(datetime.datetime.now().strftime('%H:%M:%S'), 'Error: Invalid input detected while using RL selection. Please verify inputs and correct pathing to the associated RL.js file and try again.')\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "one_forecast",
   "language": "python",
   "name": "one_forecast"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
